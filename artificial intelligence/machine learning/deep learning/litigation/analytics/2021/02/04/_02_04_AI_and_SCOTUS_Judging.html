<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Using Artificial Intelligence to Predict SCOTUS Judging | The LitKM Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Using Artificial Intelligence to Predict SCOTUS Judging" />
<meta name="author" content="Charles Dobson" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My first independent project using deep learning" />
<meta property="og:description" content="My first independent project using deep learning" />
<link rel="canonical" href="http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html" />
<meta property="og:url" content="http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html" />
<meta property="og:site_name" content="The LitKM Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-04T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html","@type":"BlogPosting","headline":"Using Artificial Intelligence to Predict SCOTUS Judging","dateModified":"2021-02-04T00:00:00-06:00","datePublished":"2021-02-04T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html"},"author":{"@type":"Person","name":"Charles Dobson"},"description":"My first independent project using deep learning","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://www.litkm.com/feed.xml" title="The LitKM Blog" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">The LitKM Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Using Artificial Intelligence to Predict SCOTUS Judging</h1><p class="page-description">My first independent project using deep learning</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-02-04T00:00:00-06:00" itemprop="datePublished">
        Feb 4, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Charles Dobson</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#artificial intelligence">artificial intelligence</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#machine learning">machine learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#deep learning">deep learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#litigation">litigation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#analytics">analytics</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/litkm/blog/tree/master/_notebooks/2021_02_04_AI_and_SCOTUS_Judging.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/litkm/blog/master?filepath=_notebooks%2F2021_02_04_AI_and_SCOTUS_Judging.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/litkm/blog/blob/master/_notebooks/2021_02_04_AI_and_SCOTUS_Judging.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h1"><a href="#Justice-Brennan">Justice Brennan </a></li>
<li class="toc-entry toc-h1"><a href="#The-Dataset">The Dataset </a></li>
<li class="toc-entry toc-h1"><a href="#The-Deep-Learning-Model">The Deep Learning Model </a></li>
<li class="toc-entry toc-h1"><a href="#The-Results">The Results </a></li>
<li class="toc-entry toc-h1"><a href="#A-Twist">A Twist </a></li>
<li class="toc-entry toc-h1"><a href="#Concluding-Thoughts">Concluding Thoughts </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021_02_04_AI_and_SCOTUS_Judging.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h1>
<p>In Prof. Wolfgang Alschner's fantastic course, <a href="https://www.datascienceforlawyers.org/">Data Science for Lawyers</a>, Lesson 8 uses machine learning to predict Justice Brennan's voting record. One of the key questions is: if a machine learning model "studies" information about thousands of Justice Brennan's cases, how well can it predict the way he voted on other cases?</p>
<p>The lesson reviews several different machine learning algorithms.<sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup> This excercise inspired me to attempt to apply a different machine learning approach to the same dataset; namely, deep learning. In this post, I detail the results of this effort.</p>
<h1 id="Justice-Brennan">
<a class="anchor" href="#Justice-Brennan" aria-hidden="true"><span class="octicon octicon-link"></span></a>Justice Brennan<a class="anchor-link" href="#Justice-Brennan"> </a>
</h1>
<p>Per <a href="https://en.wikipedia.org/wiki/William_J._Brennan_Jr.">Wikipedia</a>, Justice Brennan (1906 – 1997) was an American lawyer and jurist who served as an Associate Justice of the Supreme Court of the United States (SCOTUS) from 1956 to 1990. He was the seventh-longest-serving justice in Supreme Court history, and known for being a leader of the Court's liberal wing.</p>
<p>The length of Justice Brennan's tenure is key for present purposes. Since he sat on SCOTUS for so long, he has a lengthy voting record. This is important for "teaching" a machine learning model effectively (the more data, the better).</p>
<h1 id="The-Dataset">
<a class="anchor" href="#The-Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Dataset<a class="anchor-link" href="#The-Dataset"> </a>
</h1>
<p>The dataset is available online at the course website. The data is from <a href="http://scdb.wustl.edu/index.php">The Supreme Court Database</a>. In this database, court decisions are coded for a variety of variables relating to the identification, chronology, background, substance, and outcome of each case.</p>
<p>The dataset is a simple CSV file. <a href="https://github.com/litkm/WJBrennan-Voting/blob/main/WJBrennan_voting.csv">Click to view it in a "raw" format</a>.</p>
<p>Below, the first five entries of dataset are printed out.</p>
<p><img src="/images/copied_from_nb/my_icons/BrennanDataset.png" alt=""></p>
<p>Decoded, the first entry indicates:</p>
<ul>
<li>The case was heard in 1956 (term)</li>
<li>The petitioner (appellant) was a "bank, savings and loan, credit union, investment company" (petitioner)</li>
<li>The respondent was an "agent, fiduciary, trustee, or executor" (respondent)</li>
<li>The court assumed jurisdiction on the basis of a writ of certiorari (jurisdiction)</li>
<li>The case originated from the Pennsylvania Western U.S. District Court (caseOrigin)</li>
<li>The U.S. Court of Appeals, Third Circuit, was the source of the decision SCOTUS reviewed (caseSource)</li>
<li>SCOTUS granted the writ of certiorari in order to "to resolve important or significant question" (certReason)</li>
<li>The subject matter of the controversy related to "cruel and unusual punishment, death penalty (cf. extra legal jury influence, death penalty)" (issue)</li>
<li>The preceding variable was categorized as relating to federalism (issueArea)</li>
<li>Lastly, Justice Brennan voted with the majority (vote)</li>
</ul>
<p>Below, additional information from the dataset is set out.</p>
<p><img src="/images/copied_from_nb/my_icons/BrennanDataset2.png" alt=""></p>
<p>For present purposes, the most important information shown here is that the dataset contains 4746 entries, i.e. there is information regarding 4746 cases, including whether Justice Brennan voted with the majority or the minority of the SCOTUS panel.</p>
<h1 id="The-Deep-Learning-Model">
<a class="anchor" href="#The-Deep-Learning-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Deep Learning Model<a class="anchor-link" href="#The-Deep-Learning-Model"> </a>
</h1>
<p>Machine learning is a subfield of computer science. The basic objective is to program computers to learn so that they can perform tasks for which they were not explicitly programmed.<sup id="fnref-2" class="footnote-ref"><a href="#fn-2">2</a></sup></p>
<p>There are many approaches to machine learning, of which deep learning is only one. This approach is based on artificial neural networks, which are a kind of algorithm loosely modelled on neurons in the human brain.<sup id="fnref-3" class="footnote-ref"><a href="#fn-3">3</a></sup></p>
<p>The deep learning model I used for this project is based on a model from a lesson in the <a href="https://www.codecademy.com">Codecademy</a> course, <em>Build Deep Learning Models with TensorFlow</em>. This model is coded in a programming language called Python, and uses a deep learning framework from Google, known as Keras (TensorFlow).</p>
<p>My aim was to assemble a model that takes the Brennan dataset as an input, and outputs accurate predictions regarding his voting.</p>
<p>Critically, the model is not pre-programmed with any particular patterns, rules, or guidelines specific to Justice Brennan and the way he voted on SCOTUS. Rather, the model applies the deep learning algorithm to process the dataset and develop, independently, its own "understanding" of his voting history. Based on this understanding, it make predictions.</p>
<p>Forgive me for glossing over a lot of details. But, in simple terms, this is how the model in this project works:</p>
<ul>
<li>It randomly apportions the dataset into two subsets: one for training, and another for testing (70% for training, 30% for testing).</li>
<li>Then it looks at each case in the training dataset, one-by-one.</li>
<li>With every case, it considers each of the variables (petitioner, respondent, etc), and then predicts whether Justice Brennan voted with the majority or the minority in this particular case.</li>
<li>The model then checks the final column of the dataset: was the prediction correct or not?</li>
<li>It then recalibrates its weighting of each variable based on whether it made a correct or incorrect prediction. When a model works well, this recalibration results in incrementally better (more accurate) predictions.</li>
<li>Once the model has reviewed each of the cases in the training dataset, it then tests itself, case-by-case again, against the second (testing) dataset. This is an important way check against the model merely memorizing the training dataset, as opposed to calibrating its predictive process to enable it to generalize and make accurate predictions about new cases (the test dataset).</li>
<li>After the model cycles through both the training and the testing datasets, it repeats this process over again. Models will do this cycle many times (one hundred, in this instance - but it can be much more). Ideally, the predictive accuracy of the model increases each cycle until it plateaus when it reaches its predictive potential.  </li>
</ul>
<h1 id="The-Results">
<a class="anchor" href="#The-Results" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Results<a class="anchor-link" href="#The-Results"> </a>
</h1>
<p>So how did the model do?</p>
<p>Not too badly. It learned to predict accurately whether Justice Brennan voted with the majority or the minority of the SCOTUS panel with slightly less than 80% accuracy.</p>
<p>If you are interested in the code and the output it produces, <a href="https://github.com/litkm/WJBrennan-Voting/blob/main/WJBrennan_Voting.ipynb">click here</a>.</p>
<h1 id="A-Twist">
<a class="anchor" href="#A-Twist" aria-hidden="true"><span class="octicon octicon-link"></span></a>A Twist<a class="anchor-link" href="#A-Twist"> </a>
</h1>
<p>Of course, in the "real world" we do not have the benefit of a judge's entire voting record. Rather, we would have a record of previous votes, from which we would want to predict future votes.</p>
<p>This is the approach taken in Prof. Alschner's lesson. The dataset is not randomly split. Rather, the machine learning algorithm is trained on the voting record from 1956 until 1979, and then tested against the record from the 1980s. That is, the pre-1980 voting record is used to predict the votes from the 1980s.</p>
<p>How did my deep learning model do when the dataset was likewise apportioned? Performance dropped. At best, the model achieved about 69% accuracy.</p>
<p>I tweeted about this and Prof. Alschner kindly commented, noting the pre-1980 variables seem to miss something important for predicting the post-1980 voting.</p>
<p>This made me do some digging that I should have done at the outset (in my defence, I am a hobbyist who did not know any better at the time!).</p>
<p>Below is a graph showing Justice Brennan's votes over the entire dataset:</p>
<p><img src="/images/copied_from_nb/my_icons/BrennanDataset3.png" alt=""></p>
<p>As you can see, Justice Brennan voted with the majority slightly less than 80% of the time over the course of his entire SCOTUS tenure.</p>
<p>When we look at his record from the 1950s until the end of the 1970s, we see that he voted with the majority slightly more than 80% of the time:</p>
<p><img src="/images/copied_from_nb/my_icons/BrennanDataset4.png" alt=""></p>
<p>Finally, let's look at his voting record for the 1980s only:</p>
<p><img src="/images/copied_from_nb/my_icons/BrennanDataset5.png" alt=""></p>
<p>We now see a big drop! He voted with the majority less than 70% of the time. This may explain why the model's prediction accuracy dropped when the dataset was split to train on the pre-1980s data and test on the 1980s data.</p>
<h1 id="Concluding-Thoughts">
<a class="anchor" href="#Concluding-Thoughts" aria-hidden="true"><span class="octicon octicon-link"></span></a>Concluding Thoughts<a class="anchor-link" href="#Concluding-Thoughts"> </a>
</h1>
<p>Some final thoughts:</p>
<ul>
<li>Sometimes a simple approach will yield valuable insight. Just graphing Justice's Brennan's voting history provides enough information to make some reasonably accurate predictions. No fancy machine learning algorithms required.</li>
<li>That said, I still consider this experiment a success. The model appears to work, for one thing. At the outset, it "knows" nothing about Justice Brennan's voting record; it is simply programmed to process the dataset in a certain way. On completion, the model provides reasonably accurate predictions - better than a coin toss, in any event!</li>
<li>What about using these techniques in legal practice? Litigation analytics is already "a thing", especially in the US. In Canada, unfortunately, we suffer from a deficit of publicly available litigation data, so progress is much slower. For example, do not have an equivalent to the Supreme Court Database, discussed above, for data about the Supreme Court of Canada.</li>
</ul>
<p>Thanks for reading! Did I make a mistake? Does something not make sense? Please reach out.</p>
<p></p>
<div class="footnotes"><p id="fn-1">1. These algorithms are naive bayes, support vector machines, and K-nearest neighbor.<a href="#fnref-1" class="footnote footnotes">↩</a></p></div>
<div class="footnotes"><p id="fn-2">2. Andrew Trask, <em>Grokking Deep Learning</em> (Shelter Island, NY: Manning Publications, 2019), p. 11<a href="#fnref-2" class="footnote footnotes">↩</a></p></div>
<div class="footnotes"><p id="fn-3">3. Ibid., p. 10<a href="#fnref-3" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="litkm/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Learning to apply machine learning to litigation and practice management.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/litkm" title="litkm"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/LitigationKM" title="LitigationKM"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
