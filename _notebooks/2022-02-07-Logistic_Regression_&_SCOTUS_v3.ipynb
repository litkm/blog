{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-02-07-Logistic_Regression_&_SCOTUS-v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Logistic Regression to Predict SCOTUS Judging\n",
        "> How to Predict Justice Brennan's voting record with logistic regression\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- image: images/social_logo.png\n",
        "- author: Charles Dobson\n",
        "- categories: [python, artificial intelligence, machine learning, scikit-learn, logistic regression, law, litigation, analytics]"
      ],
      "metadata": {
        "id": "x7Hu0QjLnURu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In previous posts, I've written about using a neural network and *k*-nearest neighbor to predict SCOTUS judging.{% fn 1 %} These posts were based on lesson 8 from  Prof. Wolfgang Alschner's fantastic course, [Data Science for Lawyers](https://www.datascienceforlawyers.org/). In this lesson, Prof. Alschner reviews several machine learning algorithms and explains how to use them to predict Justice Brennan's voting record. \n",
        "\n",
        "Logistic regression is not among the algorithms Prof. Alschner discusses. I was curious about how this algorithm would perform. In this post, I apply a logistic regression model to the Justice Brennan dataset. To do this, I use the `LogisticRegression()` class from scikit-learn. \n",
        "\n",
        "# Logistic Regression\n",
        "\n",
        "In a nutshell, logistic regression is a supervised machine learning algorithm that can be used for classification. In its simpler forms, it predicts the probability of a datapoint belonging to one group or another. \n",
        "\n",
        "In this post, I use a logistic regression model to predict whether Justice Brennan votes with the majority of the court in relation to 4746 cases. \n",
        "\n",
        "# The Dataset\n",
        "\n",
        "You can find an overview of the dataset in my earlier post, [Using Artificial Intelligence to Predict SCOTUS Judging](https://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/law/general/2021/02/11/AI_and_SCOTUS_Judging.html).\n",
        "\n",
        "# Importing Dependencies\n",
        "\n",
        "As usual, we begin by importing our dependencies."
      ],
      "metadata": {
        "id": "t-nseDQLpLGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "iqKbLeYc8oHU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Splitting the Dataset\n",
        "\n",
        "The next steps to building this model are very similar to the other models I've reviewed on LitKM to date.\n",
        "\n",
        "So, we first load the dataset from a CSV and turn it into a DataFrame.\n",
        "\n",
        "Next, we split this dataset into training features and labels, and testing features and labels. \n",
        "\n",
        "In lesson 8, each model is trained on Justice Brennan's voting data prior to 1980 and tested on his voting data from 1980 and onwards. So we'll split our dataset likewise."
      ],
      "metadata": {
        "id": "qeCP2fpI8zQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'https://raw.githubusercontent.com/litkm/WJBrennan-Voting/main/WJBrennan_voting.csv'\n",
        "dataset = pd.read_csv(dataset)\n",
        "\n",
        "#Features\n",
        "x = dataset[['term', 'petitioner', 'respondent', 'jurisdiction', 'caseOrigin', 'caseSource', 'certReason', 'issue', 'issueArea']]\n",
        "\n",
        "#Labels\n",
        "y = dataset['vote']\n",
        "\n",
        "#Features for training\n",
        "X_train = x[x['term'] < 1980] \n",
        "\n",
        "#Features for testing\n",
        "X_test = x[x['term'] > 1979]  \n",
        "\n",
        "#Labels for training\n",
        "Y_train = y.iloc[0:3368]      \n",
        "\n",
        "#Labels for testing\n",
        "Y_test = y.iloc[3367:4745]    "
      ],
      "metadata": {
        "id": "rzTB8DEC89ze"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing the Dataset\n",
        "\n",
        "Now we must normalize the dataset. The features consist of numbers, all of varying ranges. So we need to scale them to use the same range.\n",
        "\n",
        "The labels consist of one of two words, either \"majority\" or \"minority\". We must convert these categorical labels into either a \"1\" (majority) or a \"0\" (minority)."
      ],
      "metadata": {
        "id": "TeGDTL3d9CU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#Scale features\n",
        "columns_for_standard = ['term', 'petitioner', 'respondent', 'jurisdiction', 'caseOrigin', 'caseSource', 'certReason', 'issue', 'issueArea']\n",
        "\n",
        "ct = ColumnTransformer([('numeric', StandardScaler(), columns_for_standard)])\n",
        "\n",
        "X_train = ct.fit_transform(X_train) \n",
        "X_test = ct.transform(X_test)\n",
        "\n",
        "#Convert categorical labels to numbers\n",
        "le = LabelEncoder()\n",
        "Y_train = le.fit_transform(Y_train.astype(str))\n",
        "Y_test = le.transform(Y_test.astype(str))"
      ],
      "metadata": {
        "id": "5BParfuc9Qrf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to create our model and train it on the dataset.\n",
        "\n",
        "# The Logistic Regression Model\n",
        "\n",
        "We instantiate our model using the `LogisticRegression()` class from scikit-learn and train it on our dataset using the `fit` method. \n"
      ],
      "metadata": {
        "id": "Bg3RPpKs9Tq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P35k0Npj9a3q",
        "outputId": "774ef96d-2d21-4961-d77b-c232509c51d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our model is trained, let's see how well it predicts Justice Brennan's voting record based on the training data."
      ],
      "metadata": {
        "id": "pqhetAXF9rOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(X_train, Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wquU-5Hp-tIX",
        "outputId": "40367c26-7d53-42af-8b33-2606d15d70ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8191805225653207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad. Using voting data from prior to 1980 only, the model predicts Justice Brennan's voting record with approximately 82% accuracy.\n",
        "\n",
        "But, trained on this data, how well does the model predict Justice Brennan's voting from 1980 onwards?"
      ],
      "metadata": {
        "id": "xfZdkCDC_H8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDNpJYBr_YMl",
        "outputId": "4f0d9507-adee-4f02-a755-1e7174f33b9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6015965166908563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieves approximately 60% accuracy. This is better than a coin toss, but not as good as the other algorithms I've reviewed on LitKM. Both KNN and the neural network achieved 69% accuracy.\n",
        "\n",
        "When working with KNN, it occurred to me that perhaps the dataset, as normalized per the approached detailed above, was incomplete. Specifically, the features and labels were not scaled to the same range. Whereas the labels use a range of 0 to 1, the features do not. \n",
        "\n",
        "Below I reproduce the code to scale the features to a range of 0 to 1, same as the labels, and fit a new logistic regression model to this updated dataset.\n"
      ],
      "metadata": {
        "id": "xtxUI_pH_cPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#Convert the features from numpy arrays to DataFrames in prep for min-max scaling, and ease of review\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "\n",
        "#Apply min-max scaling to the training features\n",
        "min = X_train.min().min()    \n",
        "max = X_train.max().max()    \n",
        "X_train = (X_train - min) / (max - min)\n",
        "\n",
        "#Apply min-max scaling to the testing features\n",
        "min = X_test.min().min()    \n",
        "max = X_test.max().max()   \n",
        "X_test = (X_test - min) / (max - min)\n",
        "\n",
        "#Convert the labels to DataFrames from numpy arrays (because the features are now DataFrames)\n",
        "Y_train = pd.DataFrame(Y_train)\n",
        "Y_test = pd.DataFrame(Y_test)\n",
        "\n",
        "#Fit a new logistic regression model with the updated dataset\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train.values.ravel())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYck53_7C-TQ",
        "outputId": "75d73f9a-e62a-4978-bf49-cfa6a5db02a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, how does this new model perform?"
      ],
      "metadata": {
        "id": "oJ7erBzaOMzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(X_train, Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvRXTdAvDVaT",
        "outputId": "948d7633-66e4-4a55-940e-c1e1ba4c3fbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8206650831353919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the training data, the model performs slightly better.\n",
        "\n",
        "But check out the results on the testing data:"
      ],
      "metadata": {
        "id": "CnTOwLbgOdal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXFTuKYoDYr7",
        "outputId": "c1d3ebb9-5085-4c70-e181-e39b246c216a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5653120464441219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Big drop! Almost 4%."
      ],
      "metadata": {
        "id": "lpqUZJx_Oo_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Thoughts\n",
        "\n",
        "With KNN, normalizing the features to likewise use a range of 0 to 1 boosted performance by about 1%. But, for logistic regression, this same change decreased perforance, and by a relatively significant amount. Candidly, at this point I have no idea why this occurred. Any ideas? I'm all ears!\n",
        "\n",
        "{{ 'See [Using Artificial Intelligence to Predict SCOTUS Judging](https://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/law/general/2021/02/11/AI_and_SCOTUS_Judging.html); [Parsing a Neural Network to Predict SCOTUS Judging](https://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/2021/02/26/Parsing_Model.html); and [Using K-Nearest Neighbor to Predict SCOTUS Judging](https://www.litkm.com/python/artificial%20intelligence/machine%20learning/scikit-learn/knn/k-nearest%20neighbor/law/litigation/analytics/2021/11/10/Python_KNN_to_Predict_SCOTUS_Voting.html).' | fndetail: 1 }}"
      ],
      "metadata": {
        "id": "cn7c0p6wpW_J"
      }
    }
  ]
}
