{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-03-12-Loading Text for NLTK in Google Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FleAG2Cr7tsO"
      },
      "source": [
        "# How to Load Text Files as a Corpus for NLTK in Google Colab\r\n",
        "> \"Featuring two approaches: in Colab or from Google Drive\"\r\n",
        "\r\n",
        "- toc: true \r\n",
        "- badges: true\r\n",
        "- comments: true\r\n",
        "- image: images/social_logo.png\r\n",
        "- author: Charles Dobson\r\n",
        "- categories: [natural language processing, preprocessing text, nltk, nlp, google colab]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gaw8MX8uil"
      },
      "source": [
        "# Introduction\r\n",
        "\r\n",
        "Most tutorials on NLTK presume you are working locally on your own machine as opposed to in a cloud environment such as Google Colab. \r\n",
        "\r\n",
        "In this blog post, I address using Google Colab to load text files for use as a corpus from:\r\n",
        "1. within Google Colab; and\r\n",
        "2. Google Drive.\r\n",
        "\r\n",
        "When I looked on the web, I did not see any articles addressing this directly. Hence this brief post.\r\n",
        "\r\n",
        "# Loading from within Google Colab\r\n",
        "\r\n",
        "First, you must upload the text files into your Colab environment.\r\n",
        "\r\n",
        "Click on the file icon located on the left side of the screen. Navigate the file structure to where you wish to store the files.\r\n",
        "\r\n",
        "By default, your Colab environment will have a `/content` subfolder. For this post, I have created a subfolder called `/content/textfiles`. This is where I then uploaded the text files for the corpus. To upload, right click on the folder where you wish the files to be placed.\r\n",
        "\r\n",
        "In the below screen shot, you will see the file structure and the \"test\" text files I uploaded:\r\n",
        "\r\n",
        "![](my_icons/colabfiles.png)\r\n",
        "\r\n",
        "Now we are ready to load the text files as a corpus. From hereon, the process is essentially the same as if you were working locally.\r\n",
        "\r\n",
        "For the limited purposes of this tutorial, the below dependencies are required.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Idq633MQMD5"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.corpus import PlaintextCorpusReader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwxFuuFuQMYH"
      },
      "source": [
        "NLTK contains a class called `PlaintextCorpusReader()` for creating a corpus from text files. \r\n",
        "\r\n",
        "In the below example, we assign the directory where the files are located to a variable (`corpus_root`). \r\n",
        "\r\n",
        "We then instantiate an instance of `PlaintextCorpusReader()` and assign it to the variable `corpus`. The parameters indicate where to find the text files, and which files to include (in this example, all of them).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_lROTS5Qjpm"
      },
      "source": [
        "corpus_root = '/content/textfiles'\r\n",
        "corpus = PlaintextCorpusReader(corpus_root, '.*')\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS5XfZF-cFcZ"
      },
      "source": [
        "To confirm the corpus has been constituted, we can call the `fileids()` method to list the files contained within the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt1KTy-TcK7B",
        "outputId": "b5857614-89ec-461f-a929-7b9d2c78c832"
      },
      "source": [
        "corpus.fileids()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_data_1.txt', 'test_data_2.txt', 'test_data_3.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OVQR0yiQPwZ"
      },
      "source": [
        "If you are using a free Colab account, each time your disconnect from the runtime environment your text files will be deleted. To avoid this, either upgrade your Colab account or use Google drive.\r\n",
        "\r\n",
        "# Loading from Google Drive\r\n",
        "\r\n",
        "The process for creating a corpus from textfiles located on your Google drive is similar to the above.\r\n",
        "\r\n",
        "First, upload the text files into your Google drive. Take note of the directory.\r\n",
        "\r\n",
        "In addition to the dependencies listed above, one more is required. This is to mount your Google drive in your Colab environment. Call the the mount method per the below and follow the instructions that result.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM2UBNZSfhmf",
        "outputId": "41da12b1-3832-4406-b9a8-cfe73be4cabb"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gNeNxKcf36k"
      },
      "source": [
        "Now your Google drive is mounted. The balance of the process is the same as above, i.e. as if you were working with the files directly in your Colab environment. Make sure to revise the file path as necessary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4CAy72jgKKU"
      },
      "source": [
        "corpus_root = '/content/drive/MyDrive/Datasets'\r\n",
        "corpus = PlaintextCorpusReader(corpus_root, '.*')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht2xH4aKgUMo"
      },
      "source": [
        "Once again, to confirm the corpus has been constituted, we can call the `fileids()` method to list the files contained within the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE68AK5RghRX",
        "outputId": "fb93d4f5-6377-4f2a-99b1-5e51ebb21def"
      },
      "source": [
        "corpus.fileids()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_data_1.txt', 'test_data_2.txt', 'test_data_3.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn1nrFA5jCG0"
      },
      "source": [
        "If you have any questions, please feel free to reach out."
      ]
    }
  ]
}
