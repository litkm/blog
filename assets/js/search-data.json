{
  
    
        "post0": {
            "title": "How to Generate Docket Narratives for NLP Experiments",
            "content": "Introduction . Lately I&#39;ve been thinking about how natural language processing techniques could possibly be applied to the docket narratives lawyers draft for their timesheets. Categorizing dockets according to phase/task codes is an obvious possibility. . But I also wonder about other potential insights; for example, to develop an understanding of the type of work associates and/or partners are doing, and the distribution of this work amongst timekeepers. Are associates being provided enough opportunities on their feet in court or conducting examinations? Are senior associates doing too much research that is better suited for junior associates? To what extent are partners doing &quot;associate&quot; work and vice versa? . There is potentially a wealth of information in docket narratives that could be used to improve the operations of a litigation department. However, in most law firms, analyzing these narratives manually would not be practical. Hence my interest in applying NLP techniques to this type of data. . Generating a Synthetic Dataset of Docket Narratives . Of course, dockets are confidential. For my experiments I need to develop a synthetic dataset. . Below is a script I wrote to generate a synthetic dataset of docket narratives. It&#39;s very simple and, admittedly, only roughly approximates genuine docket narratives. I&#39;m hoping it will be a sufficient place to start. . My first goal will simply be to see if I can train a language model to distinguish between narratives that involve drafting and those that do not. I plan try a range of supervised learning techniques, approaching this as a categorization problem. . This script generates a dataset with two columns of information. The rows in the first column contain the randomly generated docket narratives. The rows in the second column contain either a 0 or a 1. So-called drafting narratives are assigned a 1 and all other narratives are assigned a 0. These will be the labels required to train the language model. . Final Thoughts . Have you worked on this type of problem with similar data? Written anything on it? Is my dataset unsuited for this purpose? Please let me know! . Script . import random import pandas as pd #Lists consisting of the components for the docket narratives actions = [&quot;writing&quot;, &quot;drafting&quot;, &quot;editing&quot;, &quot;revising&quot;, &quot;briefing&quot;, &quot;reviewing&quot;, &quot;analyzing&quot;, &quot;preparing&quot;, &quot;proofing&quot;, &quot;researching&quot;, &quot;attending to&quot;, &quot;finalizing&quot;, &quot;considering&quot;, &quot;discussing&quot;, &quot;addressing&quot;] object = [&quot;notice of motion&quot;, &quot;affidavit&quot;, &quot;factum&quot;, &quot;memorandum&quot;, &quot;memo&quot;, &quot;compendium&quot;, &quot;book of authority&quot;, &quot;motion record&quot;, &quot;analysis&quot;, &quot;order&quot;, ] subject = [&quot;summary judgment&quot;, &quot;injunction&quot;, &quot;enforcing foreign judgment&quot;, &quot;motion to strike&quot;, &quot;refusals&quot;, &quot;disqualifying expert&quot;] dockets = [] #Function to randomly generate a docket narrative and add it to a list containing all of the narratives def add_docket(): docket = random.choice(actions) + &quot; &quot; + random.choice(object) + &quot; re: &quot; + random.choice(subject) dockets.append(docket) #While loop to generate the dataset. Edit the number to the right of the &lt; to specify the number of docket narratives you desire. x = 0 while x &lt; 10000: add_docket() x += 1 #Convert list with narratives to DataFrame df = pd.DataFrame(dockets, columns=[&#39;narrative&#39;]) #List containing the drafting words drafting = [&quot;writing&quot;, &quot;drafting&quot;, &quot;editing&quot;, &quot;revising&quot;, &quot;briefing&quot;] #Function to identify drafting narratives def is_drafting(row): for i in drafting: if i in row[&#39;narrative&#39;]: return 1 #Lambda function to review each narrative and identify the drafting narratives df[&#39;drafting&#39;] = df.apply (lambda row: is_drafting(row), axis=1) #Put a 0 in the drafting column where there is no 1 and convert the column from float to integer df[&#39;drafting&#39;] = df[&#39;drafting&#39;].fillna(0) df[&#39;drafting&#39;] = df[&#39;drafting&#39;].astype(int) #Convert DataFrame to CSV file df.to_csv(&#39;dockets&#39;) . df.head(20) . narrative drafting . 0 considering memorandum re: injunction | 0 | . 1 editing notice of motion re: summary judgment | 1 | . 2 discussing memo re: injunction | 0 | . 3 proofing memorandum re: injunction | 0 | . 4 writing motion record re: summary judgment | 1 | . 5 addressing factum re: summary judgment | 0 | . 6 addressing factum re: enforcing foreign judgment | 0 | . 7 drafting book of authority re: motion to strike | 1 | . 8 attending to compendium re: motion to strike | 0 | . 9 proofing memo re: summary judgment | 0 | . 10 addressing factum re: disqualifying expert | 0 | . 11 revising memo re: disqualifying expert | 1 | . 12 discussing analysis re: disqualifying expert | 0 | . 13 addressing notice of motion re: enforcing fore... | 0 | . 14 editing analysis re: injunction | 1 | . 15 considering affidavit re: disqualifying expert | 0 | . 16 discussing factum re: enforcing foreign judgment | 0 | . 17 addressing memorandum re: refusals | 0 | . 18 writing notice of motion re: enforcing foreign... | 1 | . 19 considering analysis re: refusals | 0 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10000 entries, 0 to 9999 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 narrative 10000 non-null object 1 drafting 10000 non-null int64 dtypes: int64(1), object(1) memory usage: 156.4+ KB . df[&#39;drafting&#39;].value_counts() . 0 6618 1 3382 Name: drafting, dtype: int64 .",
            "url": "http://www.litkm.com/python/artificial%20intelligence/machine%20learning/natural%20language%20processing/nlp/law/litigation/2022/11/14/How_to_Generate_Docket_Narratives_for_NLP_Experiments.html",
            "relUrl": "/python/artificial%20intelligence/machine%20learning/natural%20language%20processing/nlp/law/litigation/2022/11/14/How_to_Generate_Docket_Narratives_for_NLP_Experiments.html",
            "date": " • Nov 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Applying Decision Trees in Litigation",
            "content": "I recently co-authored an article about decision trees in litigation. The article is titled A Fresh Take on Applying Decision Trees in Litigation. . Note: We are talking about &quot;decision trees&quot; as in the technique from the field of decision analysis, not the machine learning algorithm. .",
            "url": "http://www.litkm.com/decision%20trees/decision%20analysis/law/litigation/2022/11/10/Decision_Trees_and_Litigation.html",
            "relUrl": "/decision%20trees/decision%20analysis/law/litigation/2022/11/10/Decision_Trees_and_Litigation.html",
            "date": " • Nov 10, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Using Logistic Regression to Predict SCOTUS Judging",
            "content": "Introduction . In previous posts, I&#39;ve written about using a neural network and k-nearest neighbor to predict SCOTUS judging.1 These posts were based on lesson 8 from Prof. Wolfgang Alschner&#39;s fantastic course, Data Science for Lawyers. In this lesson, Prof. Alschner reviews several machine learning algorithms and explains how to use them to predict Justice Brennan&#39;s voting record. . Logistic regression is not among the algorithms Prof. Alschner discusses. I was curious about how this algorithm would perform. In this post, I apply a logistic regression model to the Justice Brennan dataset. To do this, I use the LogisticRegression() class from scikit-learn. . Logistic Regression . In a nutshell, logistic regression is a supervised machine learning algorithm that can be used for classification. In its simpler forms, it predicts the probability of a datapoint belonging to one group or another. . In this post, I use a logistic regression model to predict whether Justice Brennan votes with the majority of the court in relation to 4746 cases. . The Dataset . You can find an overview of the dataset in my earlier post, Using Artificial Intelligence to Predict SCOTUS Judging. . Importing Dependencies . As usual, we begin by importing our dependencies. . import pandas as pd import numpy as np from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler, LabelEncoder from sklearn.compose import ColumnTransformer . Loading and Splitting the Dataset . The next steps to building this model are very similar to the other models I&#39;ve reviewed on LitKM to date. . So, we first load the dataset from a CSV and turn it into a DataFrame. . Next, we split this dataset into training features and labels, and testing features and labels. . In lesson 8, each model is trained on Justice Brennan&#39;s voting data prior to 1980 and tested on his voting data from 1980 and onwards. So we&#39;ll split our dataset likewise. . dataset = &#39;https://raw.githubusercontent.com/litkm/WJBrennan-Voting/main/WJBrennan_voting.csv&#39; dataset = pd.read_csv(dataset) #Features x = dataset[[&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;]] #Labels y = dataset[&#39;vote&#39;] #Features for training X_train = x[x[&#39;term&#39;] &lt; 1980] #Features for testing X_test = x[x[&#39;term&#39;] &gt; 1979] #Labels for training Y_train = y.iloc[0:3368] #Labels for testing Y_test = y.iloc[3367:4745] . Normalizing the Dataset . Now we must normalize the dataset. The features consist of numbers, all of varying ranges. So we need to scale them to use the same range. . The labels consist of one of two words, either &quot;majority&quot; or &quot;minority&quot;. We must convert these categorical labels into either a &quot;1&quot; (majority) or a &quot;0&quot; (minority). . #Scale features columns_for_standard = [&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;] ct = ColumnTransformer([(&#39;numeric&#39;, StandardScaler(), columns_for_standard)]) X_train = ct.fit_transform(X_train) X_test = ct.transform(X_test) #Convert categorical labels to numbers le = LabelEncoder() Y_train = le.fit_transform(Y_train.astype(str)) Y_test = le.transform(Y_test.astype(str)) . Now we are ready to create our model and train it on the dataset. . The Logistic Regression Model . We instantiate our model using the LogisticRegression() class from scikit-learn and train it on our dataset using the fit method. . model = LogisticRegression() model.fit(X_train, Y_train) . LogisticRegression() . Now that our model is trained, let&#39;s see how well it predicts Justice Brennan&#39;s voting record based on the training data. . print(model.score(X_train, Y_train)) . 0.8191805225653207 . Not bad. Using voting data from prior to 1980 only, the model predicts Justice Brennan&#39;s voting record with approximately 82% accuracy. . But, trained on this data, how well does the model predict Justice Brennan&#39;s voting from 1980 onwards? . print(model.score(X_test, Y_test)) . 0.6015965166908563 . The model achieves approximately 60% accuracy. This is better than a coin toss, but not as good as the other algorithms I&#39;ve reviewed on LitKM. Both KNN and the neural network achieved 69% accuracy. . When working with KNN, it occurred to me that perhaps the dataset, as normalized per the approached detailed above, was incomplete. Specifically, the features and labels were not scaled to the same range. Whereas the labels use a range of 0 to 1, the features do not. . Below I reproduce the code to scale the features to a range of 0 to 1, same as the labels, and fit a new logistic regression model to this updated dataset. . #Convert the features from numpy arrays to DataFrames in prep for min-max scaling, and ease of review X_train = pd.DataFrame(X_train) X_test = pd.DataFrame(X_test) #Apply min-max scaling to the training features min = X_train.min().min() max = X_train.max().max() X_train = (X_train - min) / (max - min) #Apply min-max scaling to the testing features min = X_test.min().min() max = X_test.max().max() X_test = (X_test - min) / (max - min) #Convert the labels to DataFrames from numpy arrays (because the features are now DataFrames) Y_train = pd.DataFrame(Y_train) Y_test = pd.DataFrame(Y_test) #Fit a new logistic regression model with the updated dataset model = LogisticRegression() model.fit(X_train, Y_train.values.ravel()) . LogisticRegression() . So, how does this new model perform? . print(model.score(X_train, Y_train)) . 0.8206650831353919 . On the training data, the model performs slightly better. . But check out the results on the testing data: . print(model.score(X_test, Y_test)) . 0.5653120464441219 . Big drop! Almost 4%. . Final Thoughts . With KNN, normalizing the features to likewise use a range of 0 to 1 boosted performance by about 1%. But, for logistic regression, this same change decreased perforance, and by a relatively significant amount. Candidly, at this point I have no idea why this occurred. Any ideas? I&#39;m all ears! . 1. See Using Artificial Intelligence to Predict SCOTUS Judging; Parsing a Neural Network to Predict SCOTUS Judging; and Using K-Nearest Neighbor to Predict SCOTUS Judging.↩ .",
            "url": "http://www.litkm.com/python/artificial%20intelligence/machine%20learning/scikit-learn/logistic%20regression/law/litigation/analytics/2022/02/07/Logistic_Regression_&_SCOTUS_v3.html",
            "relUrl": "/python/artificial%20intelligence/machine%20learning/scikit-learn/logistic%20regression/law/litigation/analytics/2022/02/07/Logistic_Regression_&_SCOTUS_v3.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Using K-Nearest Neighbor to Predict SCOTUS Judging",
            "content": "Introduction . In previous posts, I&#39;ve written about using a neural network to predict SCOTUS judging.1 These posts were based on lesson 8 from Prof. Wolfgang Alschner&#39;s fantastic course, Data Science for Lawyers. In this lesson, Prof. Alschner reviews several machine learning algorithms, including k-nearest neighbor, and explains how to use them to predict Justice Brennan&#39;s voting record. . In the course, Prof. Alschner uses the R programming language. I don&#39;t know R, but I do know some Python. So I thought I&#39;d use Python to apply k-nearest neighbor to the same Justice Brennan dataset. In this post, I show how to use the KNeighborsClassifier() class from scikit-learn for this purpose. . The Dataset . You can find an overview of the dataset in my earlier post, Using Artificial Intelligence to Predict SCOTUS Judging. . Importing Dependencies . We begin by importing our dependencies. . import pandas as pd from sklearn.preprocessing import StandardScaler, LabelEncoder from sklearn.compose import ColumnTransformer from sklearn.metrics import classification_report import numpy as np from sklearn.neighbors import KNeighborsClassifier from sklearn import metrics import matplotlib.pyplot as plt . Loading and Splitting the Dataset . We then load the dataset from a CSV and turn it into a DataFrame. . Next, we split this dataset into training features and labels, and testing features and labels. In lesson 8, the KNN model is trained on Justice Brennan&#39;s voting data prior to 1980 and tested on his voting data from 1980 and onwards. So we&#39;ll split our dataset accordingly. . dataset = &#39;https://raw.githubusercontent.com/litkm/WJBrennan-Voting/main/WJBrennan_voting.csv&#39; dataset = pd.read_csv(dataset) #Features x = dataset[[&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;]] #Labels y = dataset[&#39;vote&#39;] #Features for training X_train = x[x[&#39;term&#39;] &lt; 1980] #Features for testing X_test = x[x[&#39;term&#39;] &gt; 1979] #Labels for training Y_train = y.iloc[0:3368] #Labels for testing Y_test = y.iloc[3367:4745] . Normalizing the Dataset . Now we must normalize the dataset. The features consist of numbers, all of varying ranges. So we need to scale them to use the same range. . The labels consist of one of two words, either &quot;majority&quot; or &quot;minority&quot;. We must convert these categorical labels into either a &quot;1&quot; (majority) or a &quot;0&quot; (minority). . #Scale features columns_for_standard = [&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;] ct = ColumnTransformer([(&#39;numeric&#39;, StandardScaler(), columns_for_standard)]) X_train = ct.fit_transform(X_train) X_test = ct.transform(X_test) #Convert categorical labels to numbers le = LabelEncoder() Y_train = le.fit_transform(Y_train.astype(str)) Y_test = le.transform(Y_test.astype(str)) . Now we are ready to create our model and train it on the dataset. . The KNN Model . We instantiate our model using the KNeighborsClassifier() class from scikit-learn and train it on our dataset. . Since the lesson in Data Science for Lawyers uses 3 nearest neighbors for predictions, we&#39;ll try the same at the outset. . knn = KNeighborsClassifier(n_neighbors=3) knn.fit(X_train, Y_train) . KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=None, n_neighbors=3, p=2, weights=&#39;uniform&#39;) . Testing the Model . Now let&#39;s test the model. . y_pred = knn.predict(X_test) print(&quot;Accuracy:&quot;, metrics.accuracy_score(Y_test, y_pred)) . Accuracy: 0.6444121915820029 . Interestingly, this model does not perform as well as the KNN model in Data Science for Lawyers. Whereas our model is predicting Justice Brennan&#39;s voting record at about 64% accuracy, the model in the lesson from DSL reaches 69% (0.6879536). . This is a significant difference. I&#39;ll return to this to explore further later in this post. . Improving Model Accuracy . First, however, let&#39;s see if we can improve accuracy simply by adjusting the number of nearest neighbors the model is using to make predictions. As noted above, presently we are using 3. . In the code below, we test a range of nearest neighbor configurations, from 1-100. We then graph the results. . #Loop through nearest neighbor configurations ranging from 1-100 k = 1 accuracies = [] for k in range(1, 101): classifier = KNeighborsClassifier(n_neighbors = k) classifier.fit(X_train, Y_train) accuracies.append(classifier.score(X_test, Y_test)) k += 1 #Plot results k_list = range(1, 101) plt.xlabel(&quot;k&quot;) plt.ylabel(&quot;Validation Accuracy&quot;) plt.title(&quot;Predicting Brennan J&#39;s Voting&quot;) plt.plot(k_list, accuracies) plt.show() . Now we can see some improvements. Accuracy tops out at slightly more than 68% when using around 17 nearest neighbors. . Notwithstanding improvement, this model is still not performing as well as the one in the DSL lesson. . I believe this difference in performance is likely due either to differences in the way . the dataset was normalized; or | the configuration of the model. | . I don&#39;t propose to examine this exhaustively, but there is one avenue I&#39;d like to explore. . On further inspection, I don&#39;t think the dataset we are using is properly normalized. The features and labels are not scaled to the same range. Whereas the labels use a range of 0 to 1, the features do not. A quick inspection of the features makes this clear. . #Convert the features from numpy arrays to DataFrames in prep for min-max scaling, and ease of review X_train = pd.DataFrame(X_train) X_test = pd.DataFrame(X_test) X_train.head() . 0 1 2 3 4 5 6 7 8 . 0 -1.737337 | -0.318522 | -0.126546 | -0.352654 | -0.178368 | -0.707061 | 0.473854 | 1.343053 | 1.342225 | . 1 -1.737337 | -1.392550 | -0.126546 | -0.352654 | 1.622782 | 1.635910 | 0.877430 | 1.068775 | 1.063071 | . 2 -1.737337 | 0.362335 | -0.860241 | 0.408229 | -0.244379 | -0.021932 | -1.342238 | 0.781090 | 0.783918 | . 3 -1.737337 | -0.078783 | 2.485406 | -0.352654 | -1.140240 | -0.664769 | -1.140450 | 1.898592 | 1.900532 | . 4 -1.737337 | 0.467820 | -1.095023 | 0.408229 | 1.603922 | 1.635910 | -1.342238 | -0.334458 | -0.332697 | . Let&#39;s see what happens when we re-scale the features to also range from 0 to 1. We will use a technique called min-max scaling.2 . #Apply min-max scaling to the training features min = X_train.min().min() max = X_train.max().max() X_train = (X_train - min) / (max - min) #Apply min-max scaling to the testing features min = X_test.min().min() max = X_test.max().max() X_test = (X_test - min) / (max - min) . Let&#39;s inspect the features, post re-scaling. . X_train.head() . 0 1 2 3 4 5 6 7 8 . 0 0.0 | 0.117871 | 0.133820 | 0.115035 | 0.129514 | 0.085592 | 0.183699 | 0.255909 | 0.255840 | . 1 0.0 | 0.028644 | 0.133820 | 0.115035 | 0.279148 | 0.280239 | 0.217227 | 0.233123 | 0.232649 | . 2 0.0 | 0.174434 | 0.072866 | 0.178247 | 0.124030 | 0.142511 | 0.032824 | 0.209223 | 0.209458 | . 3 0.0 | 0.137788 | 0.350812 | 0.115035 | 0.049605 | 0.089106 | 0.049588 | 0.302062 | 0.302223 | . 4 0.0 | 0.183198 | 0.053361 | 0.178247 | 0.277582 | 0.280239 | 0.032824 | 0.116547 | 0.116693 | . This looks encouraging. To confirm, we can review the minimum and maximum values from each column. First, we&#39;ll review the minimum values. . X_train.min() . 0 0.000000 1 0.028644 2 0.051736 3 0.115035 4 0.042554 5 0.069430 6 0.016060 7 0.023569 8 0.023928 dtype: float64 . Excellent. We&#39;ve bottomed out at 0. Second, let&#39;s look at the max values. . X_train.max() . 0 0.280976 1 0.426978 2 0.458090 3 1.000000 4 0.279148 5 0.281644 6 0.233991 7 0.302108 8 0.302223 dtype: float64 . Perfect. We&#39;ve topped out at 1. So we&#39;ve confirmed all of the features are scaled to range between 0 and 1, same as the labels. . Now let&#39;s create a new model that is trained on this re-scaled dataset, and test it&#39;s accuracy. . #First, convert the labels to DataFrames from numpy arrays (because the features are now DataFrames) Y_train = pd.DataFrame(Y_train) Y_test = pd.DataFrame(Y_test) #Create and train the model knn = KNeighborsClassifier(n_neighbors=3) knn.fit(X_train, Y_train.values.ravel()) #Test the model&#39;s accuracy y_pred = knn.predict(X_test) print(&quot;Accuracy:&quot;,metrics.accuracy_score(Y_test, y_pred)) . Accuracy: 0.6509433962264151 . OK! We see some improvement. But we&#39;re still shy of 69% accuracy. . Let&#39;s try playing around again with the nearest neighbor configuration, same as before. . #Loop through nearest neighbor configurations ranging from 1-100 k = 1 accuracies = [] for k in range(1, 101): classifier = KNeighborsClassifier(n_neighbors = k) classifier.fit(X_train, Y_train.values.ravel()) accuracies.append(classifier.score(X_test, Y_test)) k += 1 #Plot results k_list = range(1, 101) plt.xlabel(&quot;k&quot;) plt.ylabel(&quot;Validation Accuracy&quot;) plt.title(&quot;Predicting Brennan J&#39;s Voting&quot;) plt.plot(k_list, accuracies) plt.show() . Boom! There we go. When configured to use around 25 nearest neighbors, this model hits a solid 69% accuracy and thus also now appears to perform slightly better than the one in the DSL lesson. . Final Thoughts . I wonder how the performance of the KNN model in lesson 8 of DSL would vary if tested using a range of k configurations. If you have done this, or otherwise have any thoughts on the performance of these models, please reach out! . 1. See Using Artificial Intelligence to Predict SCOTUS Judging and Parsing a Neural Network to Predict SCOTUS Judging.↩ . 2. For more on min-max scaling, see my earlier post, Finding Analogous Cases with K-Nearest Neighbor.↩ .",
            "url": "http://www.litkm.com/python/artificial%20intelligence/machine%20learning/scikit-learn/knn/k-nearest%20neighbor/law/litigation/analytics/2021/11/10/Python_KNN_to_Predict_SCOTUS_Voting.html",
            "relUrl": "/python/artificial%20intelligence/machine%20learning/scikit-learn/knn/k-nearest%20neighbor/law/litigation/analytics/2021/11/10/Python_KNN_to_Predict_SCOTUS_Voting.html",
            "date": " • Nov 10, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Finding Analogous Cases with K-Nearest Neighbor",
            "content": "Introduction . Partner: What others cases like this has the firm handled in the past? . Associate: Uhm... (starts thinking of search terms, cancels evening plans) . In an earlier post, I provided a brief introduction to the NearestNeighbors() class from Python&#39;s scikit-learn library. In this post, I demonstrate one way this algorithm can be applied to legal data in tabular form. The dataset I use comprises matter profiles of 10,000 (fake) cases. I show how NearestNeighbors() can be used to query the dataset to find cases that are similar to each other. . For a brief primer on KNN and further resources, please see my first post on this topic. . Applying NearestNeighbors to Legal Data . Importing Dependencies and Loading the Dataset . We begin with importing our dependencies and loading the dataset. For this demo, we only need the pandas library and the NearestNeighbors() class from scikit-learn. . The dataset is a CSV file hosted on the web (in my GitHub repository). . # Import dependencies import pandas as pd from sklearn.neighbors import NearestNeighbors # Load the dataset and remove one unnecessary column that was created when this DataFrame was converted into a CSV file df = &#39;https://raw.githubusercontent.com/litkm/KNN-Project/main/cases_dataset.csv&#39; df = pd.read_csv(df) df = df.drop(&#39;Unnamed: 0&#39;, axis=1) . The Dataset . Next, let&#39;s inspect the dataset. . # Print the first 5 rows from the DataFrame df.head() . Lawyer Matter Type Jurisdiction Industry Client Role Tort Contract Restitution Statute Injunction Jurisdiction Motion Motion to Strike Summary Judgment Claim Amount . 0 Lawyer Iota | Class Action (Securities) | British Columbia | Resources | Defendant | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 11907902 | . 1 Lawyer Beta | Class Action (Competition) | British Columbia | Retail | Plaintiff | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 16003023 | . 2 Lawyer Epsilon | Class Action (Privacy | Alberta | Pharmaceuticals | Plaintiff | 1 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 19069229 | . 3 Lawyer Eta | Action (Commercial) | Ontario | Insurance | Defendant | 0 | 1 | 1 | 0 | 1 | 0 | 1 | 0 | 1244921 | . 4 Lawyer Theta | Class Action (Securities) | British Columbia | Technology | Plaintiff | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 6633831 | . This is a dataset of matter profiles: . Each row represents one matter. | Each column indicates a feature relating to these matters. | There are ten different lawyers, eight matter types, five jurisdictions, eight industries, and three client roles. | The columns labelled Tort, Contract, Restitution, and Statute relate to causes of action. A &quot;1&quot; indicates the type of cause of action applies to a given matter, whereas a &quot;0&quot; indicates it does not. | The columns labelled Injunction, Jurisdiction Motion, Motion to Strike, and Summary Judgment relate to motions. A &quot;1&quot; indicates this type of motion occurred in a given matter, where as a &quot;0&quot; indicates it did not. | The final column, Claim Amount, specifies the dollar amount of damages the plaintiff claimed. | . By way of example, let&#39;s take a closer look at the second matter in the dataset. . # Print data at row 1 of the DataFrame display(df.iloc[1]) . Lawyer Lawyer Beta Matter Type Class Action (Competition) Jurisdiction British Columbia Industry Retail Client Role Plaintiff Tort 1 Contract 1 Restitution 1 Statute 1 Injunction 0 Jurisdiction Motion 1 Motion to Strike 1 Summary Judgment 0 Claim Amount 16003023 Name: 1, dtype: object . This entry indicates: . Lawyer Beta is the lead lawyer. | This is a competition class action filed in B.C. relating to the retail industry. | The client is the plaintiff. | The claim involves causes of action in tort, contract, restitution, and statute. | There was no injunction. | The matter involved motions relating to jurisdiction and striking a pleading, but not summary judgment. | The plaintiff claims ~$16 million in damages. | . Per the below, this dataset contains 10,000 entries, i.e. matters. . # Print summary of the DataFrame df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10000 entries, 0 to 9999 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 Lawyer 10000 non-null object 1 Matter Type 10000 non-null object 2 Jurisdiction 10000 non-null object 3 Industry 10000 non-null object 4 Client Role 10000 non-null object 5 Tort 10000 non-null int64 6 Contract 10000 non-null int64 7 Restitution 10000 non-null int64 8 Statute 10000 non-null int64 9 Injunction 10000 non-null int64 10 Jurisdiction Motion 10000 non-null int64 11 Motion to Strike 10000 non-null int64 12 Summary Judgment 10000 non-null int64 13 Claim Amount 10000 non-null int64 dtypes: int64(9), object(5) memory usage: 1.1+ MB . You can view the dataset in &quot;raw&quot; form at this link. . The content of this dataset is entirely fake. I generated it randomly. If you would like to create your own datasets for experimenting with KNN, you can find the code I used in my GitHub respository for this project. . Normalizing the Dataset . As is, the dataset is not in a form the KNN algorithm can process. We must make certain changes to it. First, we must scale the numerical features so they use a standard range. Second, we must convert the categorial features, i.e. the non-numerical features (e.g. the various lawyer names under the Lawyer column), into numbers. These two processes are forms of normalizing a dataset. . Normalizing the numerical features requires converting them, as necessary, so that each references the same range. If this step is neglected, then high magnitude numbers can disproportionately influence the outcome of the calculations the computer performs. When scaled, each feature will be weighted equally in the outcome. . In this instance, all of the numerical features are either &quot;0&quot; or &quot;1&quot;, with the exception of Claim Amount. A sensible range for this dataset, therefore, is 0 to 1. Accordingly, we must scale the Claim Account column so that this data is converted into numbers within this range. . This can be done using a technique called &quot;min-max scaling&quot;, which involves applying the following formula: . y = (x - min) / (max - min) | . That is, for each number in the Claim Amount column (x), we subtract from it the lowest Claim Amount (min), and we divide this result by the range between the highest Claim Amount (max) and the lowest Claim Amount (min). The final result is a value (y), which is a number scaled between 0 and 1. . The code to do this is detailed below. We simply apply the min-max formula to every value in the Claim Amount column. Pandas has handy methods to identify the lowest and highest values in a DataFrame column (min() and max()). . # Copy the dataset into a new DataFrame. We will refer to the preprocessed DataFrame later because it is easier to read dataset = df.copy() # Apply min-max scaling to Claim Amount; that is, y = (x - min) / (max - min) column = &#39;Claim Amount&#39; dataset[column] = (dataset[column] - dataset[column].min()) / (dataset[column].max() - dataset[column].min()) # Print the first five rows of the dataset to verify the technique worked dataset.head() . Lawyer Matter Type Jurisdiction Industry Client Role Tort Contract Restitution Statute Injunction Jurisdiction Motion Motion to Strike Summary Judgment Claim Amount . 0 Lawyer Iota | Class Action (Securities) | British Columbia | Resources | Defendant | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 0.585066 | . 1 Lawyer Beta | Class Action (Competition) | British Columbia | Retail | Plaintiff | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0.795129 | . 2 Lawyer Epsilon | Class Action (Privacy | Alberta | Pharmaceuticals | Plaintiff | 1 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 0.952412 | . 3 Lawyer Eta | Action (Commercial) | Ontario | Insurance | Defendant | 0 | 1 | 1 | 0 | 1 | 0 | 1 | 0 | 0.038099 | . 4 Lawyer Theta | Class Action (Securities) | British Columbia | Technology | Plaintiff | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0.314528 | . When we review the Claim Amount column now, we see each feature is now a number ranging between 0 and 1. If we were to review all 10,000 matters in this dataset, we would find the same result. . Next, we must convert the categorical features into numbers. For this dataset, we&#39;ll use a technique called &quot;one-hot encoding&quot;. With this approach, we create new columns for each of the different categorical features under a given column. Then, either a &quot;1&quot; or a &quot;0&quot; is assigned under each these new columns, depending on whether the feature applies to a given matter. If the feature applies, a &quot;1&quot; is used; if not, then a &quot;0&quot;. . For instance, under Client Role, there are three possible features: Plaintiff, Defendant, or Third Party. When we apply one-hot encoding to this column, we replace the generic Client Role column with three new columns: Plaintiff, Defendant, and Third Party. If the client in a given matter is a plaintiff, then a &quot;1&quot; is assigned under the Plaintiff column, and the Defendant and Third Party columns each receive a &quot;0&quot; for that particular matter. . Conveniently, Pandas has a method called get_dummies(), which can be used to apply one-hot encoding to a DataFrame containing categorical features. Below, we use this method on the columns containing categorical features in our dataset. We then print out the first matter in the dataset to verify the technique has worked. . # One-hot encode the categorical columns dataset = pd.get_dummies(dataset, columns=[&#39;Lawyer&#39;, &#39;Matter Type&#39;, &#39;Jurisdiction&#39;, &#39;Industry&#39;, &#39;Client Role&#39;]) # Print the first matter in the dataset to verify the encoding was successful display(dataset.iloc[0]) . Tort 0.000000 Contract 0.000000 Restitution 0.000000 Statute 1.000000 Injunction 1.000000 Jurisdiction Motion 1.000000 Motion to Strike 1.000000 Summary Judgment 1.000000 Claim Amount 0.585066 Lawyer_Lawyer Alpha 0.000000 Lawyer_Lawyer Beta 0.000000 Lawyer_Lawyer Delta 0.000000 Lawyer_Lawyer Epsilon 0.000000 Lawyer_Lawyer Eta 0.000000 Lawyer_Lawyer Gamma 0.000000 Lawyer_Lawyer Iota 1.000000 Lawyer_Lawyer Kappa 0.000000 Lawyer_Lawyer Theta 0.000000 Lawyer_Lawyer Zeta 0.000000 Matter Type_Action (Commercial) 0.000000 Matter Type_Action (Privacy) 0.000000 Matter Type_Action (Product Liability) 0.000000 Matter Type_Action (Securities) 0.000000 Matter Type_Class Action (Competition) 0.000000 Matter Type_Class Action (Privacy 0.000000 Matter Type_Class Action (Product Liabilty 0.000000 Matter Type_Class Action (Securities) 1.000000 Jurisdiction_Alberta 0.000000 Jurisdiction_British Columbia 1.000000 Jurisdiction_Federal 0.000000 Jurisdiction_Ontario 0.000000 Jurisdiction_Quebec 0.000000 Industry_Banking 0.000000 Industry_Construction 0.000000 Industry_Insurance 0.000000 Industry_Pharmaceuticals 0.000000 Industry_Resources 1.000000 Industry_Retail 0.000000 Industry_Technology 0.000000 Industry_Transportation 0.000000 Client Role_Defendant 1.000000 Client Role_Plaintiff 0.000000 Client Role_Third Party 0.000000 Name: 0, dtype: float64 . Per the above, we can see each categorical feature has become a separate column, and whether the feature applies or not, is indicated with a &quot;1&quot; or a &quot;0&quot;. . Our dataset is now ready to be fed into the KNN algorithm. . Creating the KNN Model . Next, we create our KNN model and load the dataset into it. As described in my first post on KNN, we do not need to code the algorithm from scratch. Rather, we can use the NearestNeighbors() class from Python&#39;s scikit-learn library. Easy, peasy! . # Initialize a NearestNeighbors() object and assign it to the variable &#39;model&#39; model = NearestNeighbors(n_neighbors=4) # Run the dataset through the KNN algorithm model.fit(dataset) . NearestNeighbors(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=None, n_neighbors=4, p=2, radius=1.0) . When we create a model of the data using KNN, the algorithm plots each matter from the dataset in a multi-dimensional space. The algorithm calculates the location of each matter based on its features. Since this dataset (once normalized) has 43 features, the algorithm plots the matters in a 43-dimensional space! . To find matter analogues, the algorithm will calculate the distance between a specified matter and those nearest to it in this 43-dimensional space. The less distance between the specified matter and those nearest to it, the more similiar the matters will be. . When we create our model per the code above, we configure the algorithm to return the four nearest neighbors to our specificed matter. The first &quot;nearest neighbor&quot; is always the specified matter itself. We&#39;ll ignore this. Instead, we&#39;ll be interested in the three other matters - i.e. the three nearest neighbors. . Now we can use our model to find matter analogues in our dataset of 10,000 cases! . Querying the Dataset . Let&#39;s look at a case. The below matter profile is at row 257 of the dataset. . # Print row 257 of the DataFrame display(df.iloc[257]) . Lawyer Lawyer Zeta Matter Type Class Action (Securities) Jurisdiction Federal Industry Insurance Client Role Defendant Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 0 Claim Amount 11953137 Name: 257, dtype: object . In the next line of code, we use the algorithm to query the dataset to identify the cases most similiar to this one. . # Print the four nearest neighbors to row 257 in the DataFrame print(model.kneighbors([dataset.iloc[257]])) . (array([[0. , 0.08120263, 1.73799853, 2.0000405 ]]), array([[ 257, 2582, 8283, 2373]])) . This code returns two lists. The first list contains the distance measurements between our specified matter and its four nearest neighbors. The second list provides the row index from the dataset for these nearest neighbors. . As noted above, the first nearest neighbor is the specified matter itself. We&#39;ll ignore it. Let&#39;s examine the second matter, located at row 2582 of our dateset. Notably, this matter has a distance measurement less than 1. We can anticipate matters 257 and 2582 will be very similar. . # Print row 2582 of the DataFrame display(df.iloc[2582]) . Lawyer Lawyer Zeta Matter Type Class Action (Securities) Jurisdiction Federal Industry Insurance Client Role Defendant Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 0 Claim Amount 10370112 Name: 2582, dtype: object . Indeed, when we compare these matters, we see they are virtually identical. They differ only in the amount of money the plaintiff is claiming. . The next nearest neighbor is matter 8283. . # Print row 8283 of the DataFrame display(df.iloc[8283]) . Lawyer Lawyer Zeta Matter Type Class Action (Securities) Jurisdiction Ontario Industry Insurance Client Role Defendant Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 1 Claim Amount 14753800 Name: 8283, dtype: object . This matter differs from our target matter in only three respects: Jurisdiction, Claim Amount, and it has a summary judgment motion. . Let&#39;s look at the last of the nearest neighbors, matter 2373. . # Print row 2373 of the DataFrame display(df.iloc[2373]) . Lawyer Lawyer Alpha Matter Type Class Action (Securities) Jurisdiction Federal Industry Insurance Client Role Plaintiff Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 0 Claim Amount 11705007 Name: 2373, dtype: object . This matter also differs from our target matter in only three respects: Lawyer, Client Role, and Claim Amount. . Conclusion . Although there are 10,000 cases in this dataset, using the KNN algorithm we can find accurate matter analogues within seconds! . That said, we need the right dataset. KNN can only take data in a structured form, and structured data is often in short supply. . Final Thoughts . Have you experimented with using KNN on legal data? Please reach out! . Appendix . For ease of review, all of the code from this post is set out below. . # Import dependencies import pandas as pd from sklearn.neighbors import NearestNeighbors # Load the dataset and remove one unnecessary column that was created when this DataFrame was converted into a CSV file df = &#39;https://raw.githubusercontent.com/litkm/KNN-Project/main/cases_dataset.csv&#39; df = pd.read_csv(df) df = df.drop(&#39;Unnamed: 0&#39;, axis=1) # Print the first 5 rows from the DataFrame df.head() # Print data at row 1 of the DataFrame display(df.iloc[1]) # Print summary of the DataFrame df.info() # Copy the dataset into a new DataFrame. We will refer to the preprocessed DataFrame later because it is easier to read dataset = df.copy() # Apply min-max scaling to Claim Amount; that is, y = (x - min) / (max - min) column = &#39;Claim Amount&#39; dataset[column] = (dataset[column] - dataset[column].min()) / (dataset[column].max() - dataset[column].min()) # Print the first five rows of the dataset to verify the technique worked dataset.head() # One-hot encode the categorical columns dataset = pd.get_dummies(dataset, columns=[&#39;Lawyer&#39;, &#39;Matter Type&#39;, &#39;Jurisdiction&#39;, &#39;Industry&#39;, &#39;Client Role&#39;]) # Print the first matter in the dataset to verify the encoding was successful display(dataset.iloc[0]) # Initialize a NearestNeighbors() object and assign it to the variable &#39;model&#39; model = NearestNeighbors(n_neighbors=4) # Run the dataset through the KNN algorithm model.fit(dataset) # Print row 257 of the DataFrame display(df.iloc[257]) # Print the four nearest neighbors to row 257 in the DataFrame print(model.kneighbors([dataset.iloc[257]])) # Print row 2582 of the DataFrame display(df.iloc[2582]) # Print row 8283 of the DataFrame display(df.iloc[8283]) # Print row 2373 of the DataFrame display(df.iloc[2373]) . Lawyer Lawyer Beta Matter Type Class Action (Competition) Jurisdiction British Columbia Industry Retail Client Role Plaintiff Tort 1 Contract 1 Restitution 1 Statute 1 Injunction 0 Jurisdiction Motion 1 Motion to Strike 1 Summary Judgment 0 Claim Amount 16003023 Name: 1, dtype: object . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10000 entries, 0 to 9999 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 Lawyer 10000 non-null object 1 Matter Type 10000 non-null object 2 Jurisdiction 10000 non-null object 3 Industry 10000 non-null object 4 Client Role 10000 non-null object 5 Tort 10000 non-null int64 6 Contract 10000 non-null int64 7 Restitution 10000 non-null int64 8 Statute 10000 non-null int64 9 Injunction 10000 non-null int64 10 Jurisdiction Motion 10000 non-null int64 11 Motion to Strike 10000 non-null int64 12 Summary Judgment 10000 non-null int64 13 Claim Amount 10000 non-null int64 dtypes: int64(9), object(5) memory usage: 1.1+ MB . Tort 0.000000 Contract 0.000000 Restitution 0.000000 Statute 1.000000 Injunction 1.000000 Jurisdiction Motion 1.000000 Motion to Strike 1.000000 Summary Judgment 1.000000 Claim Amount 0.585066 Lawyer_Lawyer Alpha 0.000000 Lawyer_Lawyer Beta 0.000000 Lawyer_Lawyer Delta 0.000000 Lawyer_Lawyer Epsilon 0.000000 Lawyer_Lawyer Eta 0.000000 Lawyer_Lawyer Gamma 0.000000 Lawyer_Lawyer Iota 1.000000 Lawyer_Lawyer Kappa 0.000000 Lawyer_Lawyer Theta 0.000000 Lawyer_Lawyer Zeta 0.000000 Matter Type_Action (Commercial) 0.000000 Matter Type_Action (Privacy) 0.000000 Matter Type_Action (Product Liability) 0.000000 Matter Type_Action (Securities) 0.000000 Matter Type_Class Action (Competition) 0.000000 Matter Type_Class Action (Privacy 0.000000 Matter Type_Class Action (Product Liabilty 0.000000 Matter Type_Class Action (Securities) 1.000000 Jurisdiction_Alberta 0.000000 Jurisdiction_British Columbia 1.000000 Jurisdiction_Federal 0.000000 Jurisdiction_Ontario 0.000000 Jurisdiction_Quebec 0.000000 Industry_Banking 0.000000 Industry_Construction 0.000000 Industry_Insurance 0.000000 Industry_Pharmaceuticals 0.000000 Industry_Resources 1.000000 Industry_Retail 0.000000 Industry_Technology 0.000000 Industry_Transportation 0.000000 Client Role_Defendant 1.000000 Client Role_Plaintiff 0.000000 Client Role_Third Party 0.000000 Name: 0, dtype: float64 . Lawyer Lawyer Zeta Matter Type Class Action (Securities) Jurisdiction Federal Industry Insurance Client Role Defendant Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 0 Claim Amount 11953137 Name: 257, dtype: object . (array([[0. , 0.08120263, 1.73799853, 2.0000405 ]]), array([[ 257, 2582, 8283, 2373]])) . Lawyer Lawyer Zeta Matter Type Class Action (Securities) Jurisdiction Federal Industry Insurance Client Role Defendant Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 0 Claim Amount 10370112 Name: 2582, dtype: object . Lawyer Lawyer Zeta Matter Type Class Action (Securities) Jurisdiction Ontario Industry Insurance Client Role Defendant Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 1 Claim Amount 14753800 Name: 8283, dtype: object . Lawyer Lawyer Alpha Matter Type Class Action (Securities) Jurisdiction Federal Industry Insurance Client Role Plaintiff Tort 0 Contract 0 Restitution 1 Statute 0 Injunction 0 Jurisdiction Motion 1 Motion to Strike 0 Summary Judgment 0 Claim Amount 11705007 Name: 2373, dtype: object . .",
            "url": "http://www.litkm.com/python/machine%20learning/scikit-learn/knn/k-nearest%20neighbor/law/2021/10/19/Part_2_KNN_&_Legal_Data-v2.html",
            "relUrl": "/python/machine%20learning/scikit-learn/knn/k-nearest%20neighbor/law/2021/10/19/Part_2_KNN_&_Legal_Data-v2.html",
            "date": " • Oct 19, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Reading List: Resources I've Found Helpful (Pinned Post)",
            "content": "Introduction . This is a non-exhaustive list of resources I&#39;ve found instructive and insightful. They run the gamut. Some are technical in focus, while others are general reading. Topics range from AI (or some subset of it) only, to law and AI. I will update this list periodically.1 . If there are any resources you&#39;d recommend, please let me know! . Text Books . Deep Learning Illustrated, John Krohn (Addison-Wesley Professional, 2019) . | Grokking Algorithms, Aditya Bhargava (Manning Publications, 2016) . | Grokking Artificial Intelligence Algorithms, Rishal Hurbans (Manning Publications, 2020) . | Grokking Deep Learning, Andrew Trask (Manning Publications, 2019) . I cannot say enough good things about this book. This is the resource that made the fundamentals of deep learning &quot;click&quot; for me. It also focuses on coding neural networks from scratch in Python, rather than using a library (e.g. Keras). I found this approach very insightful. . | Introduction to Computational Programming Using Python with Application to Understanding Data, John V. Guttag, (MIT Press, 2016) . | Python for Data Analysis, Wes McKinney (O&#39;Reilly, 2014) . | . Online Courses . Build A Machine Learning Model with Python (Skills Path), Codecademy . | Build Deep Learning Models with TensorFlow (Skills Path), Codecademy . | Computer Science (Career Path), Codecademy . | . Websites . Machine Learning Mastery | Real Python | . General Reading re: AI . Artificial Intelligence: A Guide for Thinking Humans, Melanie Mitchell (Picador, 2019) . | Becoming A Data Head: How to Think, Speak, and Understand Data Science, Statistics, and Machine Learning, Alex J Gutman and Jordan Goldmeier (Wiley, 2021) . | Possible Minds: Twenty-Five Ways of Looking at AI, ed. John Brockman (Penguin, 2020) . | The Master Algorithm, Pedro Domingos (Basic Books, 2018) . | . Presentations . How to recognize AI snake oil, Arvind Narayanan, Princeton University | . Law &amp; AI: Papers . Algorithms As Legal Decisions: Gender Gaps and Canadian Employment Law in the 21st Century, Niblett, Anthony, Available at SSRN . | Judging by the Numbers: Judicial Analytics, the Justice System and its Stakeholders, McGill, Jena and Salyzyn, Amy, Dalhousie Law Journal, 2021, Available Online . | Predicting Economic Substance Cases with Machine Learning, Alarie, Benjamin and Aidid, Abdi, Journal of Tax Practice &amp; Procedure, 2020, Available at SSRN . | The Recon Approach: A New Direction for Machine Learning in Criminal Law, Bell, Kristen and Hong, Jenny and McKeown, Nick and Voss, Catalin, Berkeley Technology Law Journal, 2021, Available at SSRN . | Using Text Analytics to Predict Litigation Outcomes, Alexander, Charlotte and Al Jadda, Khalifeh and Feizollahi, Mohammed Javad and Tucker, Anne M., Law as Data: Computation, Text, and the Future of Legal Analysis (under contract, Santa Fe Institute Press, Michael Livermore &amp; Daniel Rockmore, eds., 2018, Forthcoming)., Georgia State University College of Law, Legal Studies Research Paper No. 2018-13, Available at SSRN . | . 1. Last edited February 9, 2022.↩ .",
            "url": "http://www.litkm.com/artificial%20intelligence/data%20science/general/law/machine%20learning/python/2021/06/11/Reading_List_v3.html",
            "relUrl": "/artificial%20intelligence/data%20science/general/law/machine%20learning/python/2021/06/11/Reading_List_v3.html",
            "date": " • Jun 11, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Using Machine Learning to Find Analogues in Legal Data",
            "content": "Introduction . Have we done a budget for a case like this before? What other matters have we handled with a similar profile to this one? In which other files with characteristics like this one have we brought a summary judgment motion? . This type of question arises regularly in a law firm. Answers can sometimes be challenging. Searching databases via keywords or filters is often inefficient at best, and inadequate at worst. Hence the impetus to apply machine learning to this problem. . One approach worth exploring is the k-nearest neighbor algorithm. This is among the oldest and simplest machine learning algorithms. It is typically used for regression and classification problems. But it can also be used just to find analogues in a dataset. . In this post, I introduce the NearestNeighbors() class from the scikit-learn library. This class takes an example, x, and simply returns the element(s) in the dataset that most closely resembles it. . The K-Nearest Neighbors Algorithm . In a nutshell, KNN processes the elements of a dataset and plots each of them in a multi-dimensional space. The algorithm calculates the location of each element based on its features. The distances between these elements are then used to make predictions. . There is no shortage of excellent tutorials on the KNN algorithm. My favourites include Develop k-Nearest Neighbors in Python from Scratch on Machine Learning Mastery and The k-Nearest Neighbors Algorithm in Python on Real Python. Codecademy also addresses KNN in its Build a Machine Learning Model with Python skills path. . All of the tutorials I have studied address using KNN for classification or regression problems. For instance, . What kind of flower is this example likely to be given the measurements of particular features? (Classification) | What is the likely market price of this example of real estate given its various features such as square footage, number of bedrooms, etc? (Regression) | . These tutorials also tend either to focus on coding the KNN algorithm from scratch in Python, or using the KNeighborsClassifier() and KNeighborsRegressor() classes from scikit-learn. All of these approaches rely on calculating &quot;nearest neighbors&quot;, but this is not the output the algorithm produces. Rather, the algorithm provides a prediction regarding a classification (x is an example of category y) or a value for regression (x is valued at $y). . But what if the output you want is simply to know which elements in the dataset are the nearest neighbors to x? You could code this from scratch. Or you could use the NearestNeighbor() class from scikit-learn! . NearestNeighbors in Action . Let&#39;s apply NearestNeighbor() to a very simple dataset. . In the below snippet, we import our dependencies and create our sample dataset: five elements (rows), each with five features (columns). To create this dataset, we first define a dictionary with five keys (A to E), with each key associated with a list containing five values. This dictionary is then converted into a pandas DataFrame. . import pandas as pd from sklearn.neighbors import NearestNeighbors samples = {&#39;A&#39;: [10, 20, 30, 40, 50], &#39;B&#39;: [10, 20, 30, 40, 50], &#39;C&#39;: [10, 20, 30, 40, 50], &#39;D&#39;: [10, 20, 30, 40, 50], &#39;E&#39;: [10, 20, 30, 40, 50]} dataset = pd.DataFrame(samples) print(dataset) . A B C D E 0 10 10 10 10 10 1 20 20 20 20 20 2 30 30 30 30 30 3 40 40 40 40 40 4 50 50 50 50 50 . Now suppose we have a new element, x, and we want to know which element in our dataset is the most similar (or nearest neighbor) to it. In this example, x has a value of 9 in each column. . In the next snippet, we create a new DataFrame comprising the features for x. Then, we instantiate an instance of NearestNeighbor(), assign it to the variable neigh, and fit it to the dataset. . Finally, we run our query using the kneighbors() method to find the nearest neighbor to x. . x = {&#39;A&#39;: [9], &#39;B&#39;: [9], &#39;C&#39;: [9], &#39;D&#39;: [9], &#39;E&#39;: [9]} x = pd.DataFrame(x) neigh = NearestNeighbors(n_neighbors=1) neigh.fit(dataset) print(neigh.kneighbors(x)) . (array([[2.23606798]]), array([[0]])) . NearestNeighbor() returns 2.236 and 0, indicating the nearest neighbor to x is the element at row 0 of our dataset, and the distance between these elements is 2.236. . Let&#39;s try another example, y. This example has a value of 60 in each column. . y = {&#39;A&#39;: [60], &#39;B&#39;: [60], &#39;C&#39;: [60], &#39;D&#39;: [60], &#39;E&#39;: [60]} y = pd.DataFrame(y) print(neigh.kneighbors(y)) . (array([[22.36067977]]), array([[4]])) . As expected, the nearest neighbor to y is the element at row 4 of our dataset. . You can find more information about NearestNeighbor() in the documentation for scikit-learn. . Applying KNN to Legal Data . Admittedly, the preceding example is very abstract when considered in relation to how KNN can be implemented with legal data. Imagine each row of the dataset is one case, and each column is one feature regarding that case (e.g., jurisdiction, case type, etc.) . No sugarcoating: one of the trickiest parts to using KNN to find analogues in legal data is first putting the dataset together. This will usually involve a lot of wrangling. But, hey, it&#39;s good practice! . Final Thoughts . Have you experimented with using KNN on legal data? Hit me up! Let&#39;s compare notes. .",
            "url": "http://www.litkm.com/python/machine%20learning/scikit-learn/knn/law/2021/05/05/KNN_and_Legal_Data_v2.html",
            "relUrl": "/python/machine%20learning/scikit-learn/knn/law/2021/05/05/KNN_and_Legal_Data_v2.html",
            "date": " • May 5, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Cyborg Barristers: A Golden Age for Oral Advocacy",
            "content": "Introduction . When I was a baby litigator, I enjoyed hearing stories from senior counsel about courtroom advocacy &quot;back in the day.&quot; Oral advocacy usually featured prominently. What the lawyer said, and not so much what the lawyer wrote, was decisive. Modern civil litigation, however, relies mainly on written advocacy. . In the years to come, AI-based software tools will change litigation. Counterintuitively, I think one of these changes will be to reinvigorate the importance of oral advocacy before the Canadian courts. . Written Advocacy Has Replaced Oral Advocacy . Oral advocacy is a fading star. In a recent treatise titled Some Thoughts on Legal Writing and Written Advocacy, Justice Stratas of the Canadian Federal Court of Appeal writes: . Once upon a time, civil litigation depended exclusively on oral advocacy. That time is gone. When courts decide public law and civil cases, more and more they rely on written advocacy. . Whatever other reasons there are for this transition, complexity and volume must be chief among them. Cases are more complex than ever. They involve more documents, more experts, more law; more of everything, in short. And there are more of all of these cases! . To cope, lawyers rely on the written word to state everything they will not have time to say while before the court in person. It&#39;s a kind of buffering, if you will. . AI in Litigation Will Mainly Influence Written Advocacy . AI is already changing litigation. We see this in e-discovery, but increasingly in research, litigation analytics, and knowledge management. . To date, all AI enhanced software tools are examples of so-called narrow artificial intelligence. That is, these tools address problems or tasks relating to one specific context only. At best, narrow AI systems can be combined to increase breadth. For instance, e-discovery platforms integrate a range of AI algorithms to process data in different ways. There is no &quot;generalized&quot; legal AI that can assist with e-discovery on one day, research into case law on the next, and then prepare a first draft of a factum on the day after. . Since there is no generalized legal AI, the legal AI industry is developing in several different directions. Artificial Lawyer recently published a fascinating graphic depicting the ways legal AI has grown into branches and sub-branches. For instance, litigation analytics is branching into categories of tools addressing case law research, participant analysis (e.g. judge analytics), and drafting. There is also an emerging area of software geared towards generating drafts of legal documents; so far, there is a branch for patent applications and another for discovery responses. All AI algorithms require data. Wherever on the legal AI &quot;tree&quot; a tool may be situated, this data is mainly the written word. All of these AI systems also output data, likewise primarily in written form. This makes legal AI especially useful for lawyers’ written work product, even when an AI system is not explicitly designed for this purpose. . How AI Will Enhance Written Advocacy . Forecasting the future is obviously risky. Both the timeline, and the actual AI tools of the future, remain unclear. That said, I think the tools presently available, and under development, suggest the trajectory. . There is already intelligent software that takes legal questions (rather than just search terms), scours the case law, and provides a written response. These tools will likely improve to the point where they can provide accurate statements of law nearly ready to be dropped into a factum. . There are also tools geared towards generating full-blown legal documents. In time, I imagine we will see tools that will generate substantive first drafts of a range of documents, including notices of motion, affidavits, and factums. When the lawyer reviews these drafts, this software (or another one) will also provide options for optimizing the drafting for style and substance. . This legal drafting software will learn from the firm&#39;s own work product, work product the firm receives from opposing counsel, and anything else that is publicly available. It will further improve as it interacts with the firm&#39;s lawyers. Drafting legal documents may begin to resemble a dialogue of sorts. The machine will predict appropriate language, and the lawyer will confirm, reject, or revise. Over time, the machine should get better - much like a junior associate eventually acquires the experience to become a seasoned corner office partner. . AI tools may also help simplify cases. Even the most complex cases usually boil down to a handful of truly key documents and principles. An AI tool trained on a firm&#39;s experience with similar cases, and the case law, might assist lawyers in focusing their written submissions with better precision. . Two streams are now converging: the present emphasis on written advocacy will combine with AI litigation software, and this software will mainly improve lawyers&#39; written work. This is where the impact will be felt first and foremost. But one indirect result of this combination will be to reinvigorate the importance of oral advocacy. Let me explain. . As AI Enhances Written Advocacy, Oral Advocacy Will Become More Important . At least for the foreseeable future, all forthcoming AI tools for litigation will be narrow AI systems. They will each do one thing, or multiple closely related things, only. Eventually, some of them should also do this one thing (or things) really well. . Most, if not all, of these tools will mainly enhance written advocacy. As I described, they will facilitate legal research, prepare drafts of written submissions, and then assist with editing. Eventually, we should see fewer differences in style and quality. These tools will probably also help with distilling even the most complex cases into key components, so court filings become concise. . Once uptake among lawyers becomes widespread, the quality of written submissions of every kind will improve across the market. Although adopting new technology occurs slowly in the legal industry, its steady march is undeniable. The very best written advocacy Canada&#39;s lawyers presently have on offer should eventually become the baseline. . As the standard for written advocacy levels off on a high plateau, oral advocacy will become more important. Based on present trends, AI is not poised to enhance oral advocacy in any way comparable to written advocacy. At the same time, court hearings, whether in-person or remote, are fundamental to civil litigation in Canada. Our system also remains adversarial. There is no serious sign of either of these features changing. If written advocacy becomes generally less persuasive (because it is all so good!), then litigators must focus their efforts more on the only avenue of persuasion that remains: oral advocacy. This is where the advocate, with no (or limited) assistance from a machine, may yet make a difference in pleading the client&#39;s case. . Final Thoughts . In this post, I&#39;ve tried to sketch some possibilities for AI-based litigation tools given the evident trends. Whatever specific tools are actually developed, I believe we can be confident they will mainly enhance lawyers&#39; written work, and thereby their written advocacy. While one might be tempted to conclude this will further diminish the importance of oral advocacy, I think the opposite is likely. Current trends in AI are cuing oral advocacy up to become more important than ever. Maybe it will not define civil litigation as it did in the days of yore, but I think it could still become decisive in a way it has not been for awhile now.1 . 1. That is, of course, until AI researchers achieve a &quot;master legal algorithm&quot; and courts, featuring judges in the flesh and blood, are no longer required!↩ .",
            "url": "http://www.litkm.com/artificial%20intelligence/machine%20learning/litigation/law/lawyering/general/2021/03/29/Cyborg_Barristers.html",
            "relUrl": "/artificial%20intelligence/machine%20learning/litigation/law/lawyering/general/2021/03/29/Cyborg_Barristers.html",
            "date": " • Mar 29, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "How to Load Text Files as a Corpus for NLTK in Google Colab",
            "content": "Introduction . Most tutorials on NLTK presume you are working locally as opposed to in a cloud environment such as Google Colab. . In this blog post, I address using Google Colab to load text files for use as a corpus from: . within Google Colab; and | Google Drive. | When I looked on the web, I did not see any articles addressing this directly. Hence this brief post. . Loading from within Google Colab . First, you must upload the text files into your Colab environment. . Click on the file icon located on the left side of the screen. Navigate the file structure to where you wish to store the files. . By default, your Colab environment will have a /content subfolder. For this post, I created a subfolder called /content/textfiles. This is where I then uploaded the text files for the corpus. To upload, right click on the folder where you wish the files to be placed. . In the below screen shot, you see the file structure and the &quot;test&quot; text files I uploaded. . . Now we are ready to load the text files as a corpus. From hereon, the process is essentially the same as if you were working locally. . For the limited purposes of this tutorial, the below dependencies are required. . import nltk from nltk.corpus import PlaintextCorpusReader . NLTK contains a class called PlaintextCorpusReader() for creating a corpus from text files. . In the below example, we assign the directory where the files are located to a variable (corpus_root). . We then instantiate an instance of PlaintextCorpusReader() and assign it to the variable corpus. The parameters indicate where to find the text files, and which files to include (in this example, all of them). . Finally, to confirm the corpus has been constituted, we call the fileids() method to list the files contained within the corpus. . corpus_root = &#39;/content/textfiles&#39; corpus = PlaintextCorpusReader(corpus_root, &#39;.*&#39;) corpus.fileids() . [&#39;test_data_1.txt&#39;, &#39;test_data_2.txt&#39;, &#39;test_data_3.txt&#39;] . If you are using a free Colab account, each time your disconnect from the runtime environment your files will be deleted. To avoid this, either upgrade your Colab account or use Google drive. . Loading from Google Drive . The process for creating a corpus from text files located on your Google Drive is similar to the above. These instructions assume you are using the same Google account for both Colab and Google Drive. . First, upload the text files into your Google Drive. Take note of the directory. . In addition to the dependencies listed above, one more is required. This is to mount your Google Drive in your Colab environment. Then call the the mount method and follow the instructions that result. . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . Now your Google Drive is mounted. The balance of the process is the same as above, i.e. as if you were working with the files directly in your Colab environment. Make sure to revise the file path as necessary. . corpus_root = &#39;/content/drive/MyDrive/Datasets&#39; corpus = PlaintextCorpusReader(corpus_root, &#39;.*&#39;) corpus.fileids() . [&#39;test_data_1.txt&#39;, &#39;test_data_2.txt&#39;, &#39;test_data_3.txt&#39;] . Now you are ready to start processing your corpus! . If you have any questions, please feel free to reach out. .",
            "url": "http://www.litkm.com/natural%20language%20processing/preprocessing%20text/nltk/nlp/google%20colab/2021/03/12/Loading_Text_for_NLTK_in_Google_Colab.html",
            "relUrl": "/natural%20language%20processing/preprocessing%20text/nltk/nlp/google%20colab/2021/03/12/Loading_Text_for_NLTK_in_Google_Colab.html",
            "date": " • Mar 12, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Parsing a Neural Network for Predicting SCOTUS Judging",
            "content": "Introduction . In a recent posted titled Using Artificial Intelligence to Predict SCOTUS Judging, I discussed a machine learning model I used to make predictions regarding Justice Brennan&#39;s voting record on the Supreme Court of the United Status (SCOTUS). This model is a neural network, coded in Python, and uses the Keras framework. In the present post, I review the code, line-by-line, and explain it. . This post focuses on code and not the dataset. For more information regarding the latter, please see my earlier post (though it&#39;s worth repeating I obtained the dataset from from Prof. Alschner&#39;s great site, Data Science For Lawyers). . Further, as noted in the README for this blog, I&#39;m assuming the reader has a basic level of familiarity with object oriented programming and common Python libraries. . That said, I&#39;m also aiming to write this in a way so that a general reader will still be able to follow along (more or less). If you are interested in this content but I&#39;m assuming too much background knowledge, please let me know. I&#39;d be happy to explain further. . For reference, I developed the model using Google Colab. . Workflow . Before delving into the details, this is the workflow underpinning the code: . Import modules | Load data | Define the training set and testing set | Preprocess the data | Define the model | Run the model | Report on the results | Modules . We begin our script by loading the modules we require. These are our tools to preprocess the data and assemble the model. This model does not involve coding any functions or classes from scratch. We are not building any new tools. Instead, we import everything we need. As a result, this script is remarkably short. . import pandas as pd from sklearn.preprocessing import StandardScaler, LabelEncoder from sklearn.model_selection import train_test_split from sklearn.compose import ColumnTransformer from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, InputLayer from sklearn.metrics import classification_report from tensorflow.keras.utils import to_categorical import numpy as np . In brief, we import libraries or portions thereof from: . pandas - for loading the data regarding Justice Brennan&#39;s voting record | Scikit-learn - for preprocessing the data | NumPy - to help with the reporting; and, of course | Keras - the framework this model uses | . Data . At this step, our objective is to load the data into a pandas DataFrame. Once in this format, we can begin preprocessing it for the model to analyze. . dataset = &#39;https://raw.githubusercontent.com/litkm/WJBrennan-Voting/main/WJBrennan_voting.csv&#39; dataset = pd.read_csv(dataset) . We obtain our data from a CSV file. For convenience, I uploaded it to GitHub (in raw format). We then create a variable and assign it to the web address where the file is located. . Next, we pass this variable into the the pandas read_csv() method to load the CSV file as a DataFrame, and reassign the variable for the CSV file to now be the variable for the DataFrame. . Training Set and Testing Set . To train this model, we must split the data into training and test sets. The model &quot;learns&quot; from the training data; during the learning phase, the test data is excluded from review. Once it completes a learning phase, the model switches to a test phase, where it evaluates its predictive capacity (i.e. how well it learned from the training data) using the test data. . This model uses supervised learning. Often, this is framed in terms of x and y variables: . x represents the data inputted into the model. These inputs are sometimes called features. | y represents an outcome the model is to predict. This is sometimes called the target variable or label. | . During training, the model processes the features and uses them to make predictions. These predictions are compared against the corresponding label. The outcome of this comparison is a &quot;supervisory signal&quot;, i.e. whether the prediction was correct or not; and, if not, by how much. The model then uses this &quot;signal&quot; to recalibrate with the objective of improving its predictive capacity. . With this in mind, we need to identify our x and y variables in the Justice Brennan dataset. The first five rows of the dataset is reproduced below: . . Our target variable for this model is the outcome identified in the &quot;vote&quot; column, i.e. whether Justice Brennan voted with the majority or the minority. This is what we want to predict in respect of each row (where each row represents one SCOTUS case). . The data in the preceding columns comprises the information we intend to input into the model, and which the model will use to predict the target variables. . During training, the model will review each row of features, case by case, and make a prediction relating to that case. This prediction will then be compared to the label for that case, i.e. whether Brennan voted with the majority or not. This comparison provides the supervisory signal. Based on the result, the model recalibrates and proceeds to the next row in the dataset, i.e. the next case. . After the model cycles through the training dataset, it then evaluates its predictive capacity against the test dataset. . To provide the foregoing, we must split the original dataset into four subsets: . X_train - the set of features for training | Y_train - the corresponding set of labels for training | X_test - the set of features for testing | Y_test - the correspondence set of labels for testing | We accomplish this in a few steps. . First, we split the DataFrame into features and labels: . y = dataset[&#39;vote&#39;] x = dataset[[&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;]] . We now have a DataFrame assigned to a variable called y, and it contains all of the labels. . We now also have a DataFrame assigned to a variable called x, and it contains all of the features. . Next, we further split these two DataFrames into training sets (X_train and Y_train) and test sets (X_test and Y_test). To do this, we use the test_train_split() function from the sci-kit learn library: . X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state = 0) . As you see, test_train_split takes several parameters: . x - representing DataFrame of features to be split | y - representing the DataFame of labels to be split | test_size - this parameter specifies the size of the test set; in this instance, we allocate 30% of the dataset for testing | random_state - this parameter controls the shuffling (randomization) applied to the data before applying the split | . When calling this function, we assign the data subsets to the variables X_train, Y_train, X_test, and Y_test. Now we are ready to proceed to the next stage. . Preprocessing the Data . Before the data can be fed into the model, it must be preprocessed for optimal results. In this instance, we need to: . Scale the features | Convert the labels from categories to integers | As you can see from the printout of the dataset above, all of the features are represented using numbers. Based on the first five rows alone, we note dissimilarity; for example: . respondent - ranges from 3 to 369 | jurisdiction - ranges from 1 to 2 | issue - ranges from 40,070 to 120,020 | . If we were to dive into the rest of the dataset, we would see this dissimilarity is representative. Each of the columns has a different range, mean, etc. . When we scale the features, the model recalculates the numbers that comprise the features so that there is zero mean variance between them. . To accomplish this, we use another tool from the sci-kit learn library, namely the ColumnTransformer() class. . columns_for_standard = [&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;] ct = ColumnTransformer([(&#39;numeric&#39;, StandardScaler(), columns_for_standard)]) X_train = ct.fit_transform(X_train) X_test = ct.transform(X_test) . For convenience, we first assign the features we wish to scale to a variable called columns_for_standard. This variable is used in the next line of code. . Then, we create a ColumnTransformer() object assigned to the variable ct. When initializing this object, we configure the form of scaling and specify the features to be scaled. . Next, we use the related class methods, fit_transform() and transform(), to apply the scaler to the features. Each of these methods produces NumPy arrays comprising the now scaled features. These arrays are converted back into DataFrames and assigned, respectively, to our X_train and X_test variables. Done! We&#39;ve scaled our features. . Now to convert the labels from categories to integers (whole numbers) and ensure they, too, are scaled. On review of the &quot;vote&quot; column above, you will note there are no numbers. Rather, there is only the word &quot;majority&quot;. Throughout the dataset, the &quot;vote&quot; column only ever has the word &quot;majority&quot; or &quot;minority&quot; under it. To make these &quot;categories&quot; digestable for the model, we must convert them into integers and scale them. . Here again, we use a tool from the sci-kit learn library, namely the LabelEncoder() class along with the pandas class method astype(). . le = LabelEncoder() Y_train = le.fit_transform(Y_train.astype(str)) Y_test = le.transform(Y_test.astype(str)) Y_train = to_categorical(Y_train) Y_test = to_categorical(Y_test) . We first initialize a LabelEncoder() object and assign it to the variable le. . Then, for each of Y_train and Y_test, we call the astype() method to convert the categories (i.e. words) into integers, while calling the LabelEncoder() class methods fit_transform() and transform(), as applicable, to scale each of these DataFrames, too. . We must then use a Keras function called to_categorical() to convert the integers in Y_train and Y_test into a form called one-hot-encodings, which the model requires to factor properly for the &quot;supervisory signals&quot; discussed above. . At this point, we are finally ready to create the neural network itself. . Define the Neural Network . To create the neural network, we use Keras&#39; Sequential() class. This is one of the most popular types of models and provides for adding layers to the neural network, one after the other in a straightforward way. . We need to sepecify: . An input layer | Any hidden layers | The output layer | Below is a diagram of a simple neural network: . . The model we are building is also very simple and is likewise commprised of only three layers: an input layer, one hidden layer, and then the output layer. The code to create this is below. . model = Sequential() model.add(InputLayer(input_shape=(X_train.shape[1],))) model.add(Dense(10, activation=&#39;relu&#39;)) model.add(Dense(2, activation=&#39;softmax&#39;)) . We invoke the Sequential() class and assign it to the variable model. Then, we add the input layer. We configure it (the input_shape parameter) so that there is one input unit (&quot;synthetic neuron&quot;) for each type of feature in the X_train DataFrame. The example model in the diagram above has two input units (the circles in the input layer). By contrast, this model has nine input units because the dataset has nine different types of features. . Then, we add the hidden layer and the output layer. The integers &quot;10&quot; and &quot;2&quot; indicate the number of neurons in each layer. The activation parameter is a setting that configures some of the math the model performs each time a row (i.e. case) from the dataset is passed through the neural network. . Now we need to &quot;compile&quot; our model. Among other things, the below line of code further configures the math the model uses across all layers of the neural network when processing the dataset. . model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) . Running the Model . At this stage, we are finally ready to run our model. To do this, we use Keras&#39; fit() method with the following paramaters: . X_train - the training features | Y_train - the training labels | epochs - the numbers of times the model cycles through the entire dataset | batch_size - the number of rows from the dataset (i.e. cases) the model will feed through the neural network before recalibrating in response to the supervisory signals | verbose - set to 1 tells the model to print its progress to the screen | validation_data - indicates the test features and test labels to use during the testing phase | . model.fit(X_train, Y_train, epochs=5, batch_size=8, verbose=1, validation_data=(X_test, Y_test)) . Epoch 1/5 416/416 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.7953 - val_loss: 0.4750 - val_accuracy: 0.7795 Epoch 2/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4468 - accuracy: 0.7929 - val_loss: 0.4782 - val_accuracy: 0.7767 Epoch 3/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.7908 - val_loss: 0.4727 - val_accuracy: 0.7767 Epoch 4/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.7932 - val_loss: 0.4746 - val_accuracy: 0.7704 Epoch 5/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4479 - accuracy: 0.7908 - val_loss: 0.4770 - val_accuracy: 0.7760 . &lt;tensorflow.python.keras.callbacks.History at 0x7fabab0d4e50&gt; . The output above suggests the model learns from the data fairly quickly. After one round of training, training accuracy is ~80% and testing accuracy is ~77%. Sometimes when I&#39;ve run this model, training accuracy after the first round has been around ~62%; testing accuracy has also been lower than this example. However, by the second round the model seems consistently to max out at around ~79%-80% training accuracy and ~77%-78% testing accuracy, per around. . I&#39;ve played around a bit with the hyperparameters (i.e. the configuration of the model in terms of layers, number of neurons, number of layers, epochs, etc.), and have yet to improve performance materially. So I&#39;ve stuck with the simplest implementation of this model for this post. . Reporting the Results . To evaluate the performance of the model over all epochs, we can use Keras&#39; evaluate() method. . loss, acc = model.evaluate(X_test, Y_test, verbose=0) print(&quot;Loss:&quot;, loss, &quot;Accuracy:&quot;, acc) . Loss: 0.4769740104675293 Accuracy: 0.7759831547737122 . These lines of code evaluate the model using the testing data (X_test) and the testing labels (Y_test), and outputs (prints) the results. Overall, the model accurately predicted Justice Brennan&#39;s vote with ~78% accuracy. . The other Loss number is a calculation relating to how far off the mark the model&#39;s predictions were, overall. The closer this number is to 0, the better. This number can also be used to tune the model and further details will have to wait for another post. . Final Thoughts . My comments on the foregoing code glosses over a lot of detail, particularly in terms of the calculcations the model performs. I am planning to address this in a future post. . Candidly, I still don&#39;t understand everything that is going on in the code discussed. But it seems to work. . Thanks for reading! Did I make a mistake? Does something not make sense? Hit me up. . Appendix . For ease of review, the entire script is set out below. . import pandas as pd from sklearn.preprocessing import StandardScaler, LabelEncoder from sklearn.model_selection import train_test_split from sklearn.compose import ColumnTransformer from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, InputLayer from sklearn.metrics import classification_report from tensorflow.keras.utils import to_categorical import numpy as np dataset = &#39;https://raw.githubusercontent.com/litkm/WJBrennan-Voting/main/WJBrennan_voting.csv&#39; dataset = pd.read_csv(dataset) y = dataset[&#39;vote&#39;] x = dataset[[&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;]] X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state = 0) columns_for_standard = [&#39;term&#39;, &#39;petitioner&#39;, &#39;respondent&#39;, &#39;jurisdiction&#39;, &#39;caseOrigin&#39;, &#39;caseSource&#39;, &#39;certReason&#39;, &#39;issue&#39;, &#39;issueArea&#39;] ct = ColumnTransformer([(&#39;numeric&#39;, StandardScaler(), columns_for_standard)]) X_train = ct.fit_transform(X_train) X_test = ct.transform(X_test) le = LabelEncoder() Y_train = le.fit_transform(Y_train.astype(str)) Y_test = le.transform(Y_test.astype(str)) Y_train = to_categorical(Y_train) Y_test = to_categorical(Y_test) model = Sequential() model.add(InputLayer(input_shape=(X_train.shape[1],))) model.add(Dense(10, activation=&#39;relu&#39;)) model.add(Dense(2, activation=&#39;softmax&#39;)) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) model.fit(X_train, Y_train, epochs=5, batch_size=8, verbose=1, validation_data=(X_test, Y_test)) loss, acc = model.evaluate(X_test, Y_test, verbose=0) print(&quot;Loss:&quot;, loss, &quot;Accuracy:&quot;, acc) . Epoch 1/5 416/416 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7485 - val_loss: 0.4861 - val_accuracy: 0.7669 Epoch 2/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4716 - accuracy: 0.7776 - val_loss: 0.4800 - val_accuracy: 0.7788 Epoch 3/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.7794 - val_loss: 0.4776 - val_accuracy: 0.7809 Epoch 4/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.7838 - val_loss: 0.4758 - val_accuracy: 0.7802 Epoch 5/5 416/416 [==============================] - 1s 1ms/step - loss: 0.4497 - accuracy: 0.7912 - val_loss: 0.4755 - val_accuracy: 0.7809 Loss: 0.47549518942832947 Accuracy: 0.7808988690376282 .",
            "url": "http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/2021/02/26/Parsing_Model.html",
            "relUrl": "/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/2021/02/26/Parsing_Model.html",
            "date": " • Feb 26, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "A README re: this Blog (Pinned Post)",
            "content": "As I write this, my plan for this blog is to focus mainly on technical concepts and code. Most posts will presume a familiarity with programming in general and, in particular, Python. Mind you, I won&#39;t presume deep familiarity. I can&#39;t. My own understanding is too shallow! . That said, I am aiming to include a law angle as often as possible (especially litigation), and I will draft many of these posts with a general, non-technical reader in mind. So, someone who is involved in law and also interested in artificial intelligence, legal tech, etc. To find these posts efficiently, you can use the &quot;Tags&quot; function at the top right-hand of your screen and look under the tag &quot;general&quot;. . Of course, if you have any questions (or corrections!) about anything you read on this site, I would be grateful to hear from you. You can reach me via the &quot;About Me&quot; page. .",
            "url": "http://www.litkm.com/law/litigation/general/2021/02/19/How_to_Read_this_Blog.html",
            "relUrl": "/law/litigation/general/2021/02/19/How_to_Read_this_Blog.html",
            "date": " • Feb 19, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Using Artificial Intelligence to Predict SCOTUS Judging",
            "content": "Introduction . In Prof. Wolfgang Alschner&#39;s fantastic course, Data Science for Lawyers, Lesson 8 uses machine learning to predict Justice Brennan&#39;s voting record. One of the key questions is: if a machine learning model &quot;studies&quot; information about thousands of Justice Brennan&#39;s cases, how well can it predict the way he voted on other cases? . The lesson reviews several different machine learning algorithms.1 This excercise inspired me to attempt to apply a different machine learning approach to the same dataset; namely, deep learning. In this post, I detail the results of this effort. . Justice Brennan . Per Wikipedia, Justice Brennan (1906 – 1997) was an American lawyer and jurist who served as an Associate Justice of the Supreme Court of the United States (SCOTUS) from 1956 to 1990. He was the seventh-longest-serving justice in Supreme Court history, and known for being a leader of the Court&#39;s liberal wing. . The length of Justice Brennan&#39;s tenure is key for present purposes. Since he sat on SCOTUS for so long, he has a lengthy voting record. This is important for &quot;teaching&quot; a machine learning model effectively (the more data, the better). . The Dataset . The dataset is available online at the course website. The data is from The Supreme Court Database. In this database, court decisions are coded for a variety of variables relating to the identification, chronology, background, substance, and outcome of each case. . The dataset is a simple CSV file. Click to view it in a &quot;raw&quot; format. . Below, the first five entries of dataset are printed out. . . Decoded, the first entry indicates: . The case was heard in 1956 (term) | The petitioner (appellant) was a &quot;bank, savings and loan, credit union, investment company&quot; (petitioner) | The respondent was an &quot;agent, fiduciary, trustee, or executor&quot; (respondent) | The court assumed jurisdiction on the basis of a writ of certiorari (jurisdiction) | The case originated from the Pennsylvania Western U.S. District Court (caseOrigin) | The U.S. Court of Appeals, Third Circuit, was the source of the decision SCOTUS reviewed (caseSource) | SCOTUS granted the writ of certiorari in order to &quot;to resolve important or significant question&quot; (certReason) | The subject matter of the controversy related to &quot;cruel and unusual punishment, death penalty (cf. extra legal jury influence, death penalty)&quot; (issue) | The preceding variable was categorized as relating to federalism (issueArea) | Lastly, Justice Brennan voted with the majority (vote) | . Below, additional information from the dataset is set out. . . For present purposes, the most important information shown here is that the dataset contains 4746 entries, i.e. there is information regarding 4746 cases, including whether Justice Brennan voted with the majority or the minority of the SCOTUS panel. . The Deep Learning Model . Machine learning is a subfield of computer science. The basic objective is to program computers to learn so that they can perform tasks for which they were not explicitly programmed.2 . There are many approaches to machine learning, of which deep learning is only one. This approach is based on artificial neural networks, which are a kind of algorithm loosely modelled on neurons in the human brain.3 . The deep learning model I used for this project is based on a model from a lesson in the Codecademy course, Build Deep Learning Models with TensorFlow. This model is coded in a programming language called Python, and uses a deep learning framework from Google, known as Keras (TensorFlow). . My aim was to assemble a model that takes the Brennan dataset as an input, and outputs accurate predictions regarding his voting. . Critically, the model is not pre-programmed with any particular patterns, rules, or guidelines specific to Justice Brennan and the way he voted on SCOTUS. Rather, the model applies the deep learning algorithm to process the dataset and develop, independently, its own &quot;understanding&quot; of his voting history. Based on this understanding, it make predictions. . Forgive me for glossing over a lot of details. But, in simple terms, this is how the model in this project works: . It randomly apportions the dataset into two subsets: one for training, and another for testing (70% for training, 30% for testing). | Then it looks at each case in the training dataset, one-by-one. | With every case, it considers each of the variables (petitioner, respondent, etc), and then predicts whether Justice Brennan voted with the majority or the minority in this particular case. | The model then checks the final column of the dataset: was the prediction correct or not? | It then recalibrates its weighting of each variable based on whether it made a correct or incorrect prediction. When a model works well, this recalibration results in incrementally better (more accurate) predictions. | Once the model has reviewed each of the cases in the training dataset, it then tests itself, case-by-case again, against the second (testing) dataset. This is an important way check against the model merely memorizing the training dataset, as opposed to calibrating its predictive process to enable it to generalize and make accurate predictions about new cases (the test dataset). | After the model cycles through both the training and the testing datasets, it repeats this process over again. Models will do this cycle many times (one hundred, in this instance - but it can be much more). Ideally, the predictive accuracy of the model increases each cycle until it plateaus when it reaches its predictive potential. | . The Results . So how did the model do? . Not too badly. It learned to predict accurately whether Justice Brennan voted with the majority or the minority of the SCOTUS panel with slightly less than 80% accuracy. . If you are interested in the code and the output it produces, click here. . The Real World . Of course, in the &quot;real world&quot; we do not have the benefit of a judge&#39;s entire voting record. Rather, we would have a record of previous votes, from which we would want to predict future votes. . This is the approach taken in Prof. Alschner&#39;s lesson. The dataset is not randomly split. Rather, the machine learning algorithm is trained on the voting record from 1956 until 1979, and then tested against the record from the 1980s. That is, the pre-1980 voting record is used to predict the votes from the 1980s. . How did my deep learning model do when the dataset was likewise apportioned? Performance dropped. At best, the model achieved about 69% accuracy. . I tweeted about this and Prof. Alschner kindly commented, noting the pre-1980 variables seem to miss something important for predicting the post-1980 voting. . This made me do some digging that I should have done at the outset (in my defence, I am a hobbyist who did not know any better at the time!). . Below is a graph showing Justice Brennan&#39;s votes over the entire dataset (on the x axis, 0 means a minority vote and 1 means a majority vote): . . As you can see, Justice Brennan voted with the majority slightly less than 80% of the time over the course of his entire SCOTUS tenure. . When we look at his record from the 1950s until the end of the 1970s, we see that he voted with the majority slightly more than 80% of the time: . . Finally, let&#39;s look at his voting record for the 1980s only: . . We now see a big drop! He voted with the majority less than 70% of the time. This may explain why the model&#39;s prediction accuracy dropped when the dataset was split to train on the pre-1980s data and test on the 1980s data. . Concluding Thoughts . Some final thoughts: . Sometimes a simple approach will yield valuable insight. Just graphing Justice&#39;s Brennan&#39;s voting history provides enough information to make some reasonably accurate predictions. No fancy machine learning algorithms required. | That said, I still consider this experiment a success. The model appears to work, for one thing. At the outset, it &quot;knows&quot; nothing about Justice Brennan&#39;s voting record; it is simply programmed to process the dataset in a certain way. On completion, the model provides reasonably accurate predictions - better than a coin toss, in any event! | What about using these techniques in legal practice? Litigation analytics is already &quot;a thing&quot;, especially in the US. In Canada, unfortunately, we suffer from a deficit of publicly available litigation data, so progress is much slower. For example, do not have an equivalent to the Supreme Court Database, discussed above, for data about the Supreme Court of Canada. | . Thanks for reading! Did I make a mistake? Does something not make sense? Please reach out. . 1. These algorithms are naive bayes, support vector machines, and K-nearest neighbor.↩ . 2. Andrew Trask, Grokking Deep Learning (Shelter Island, NY: Manning Publications, 2019), p. 11↩ . 3. Ibid., p. 10↩ .",
            "url": "http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/law/general/2021/02/11/AI_and_SCOTUS_Judging.html",
            "relUrl": "/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/python/keras/neural%20networks/law/general/2021/02/11/AI_and_SCOTUS_Judging.html",
            "date": " • Feb 11, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "ghtop redux",
            "content": ". Introduction . We recently refactored the CLI tool ghtop, created by the CEO of GitHub, Nat Friedman. Nat even described our refactor as a “tour de force”. This post describes what we learned along the way. . Motivation . Recently, we released ghapi, a new python client for the GitHub API. ghapi provides unparalleled ease of access to the GitHub api, as well as utilities for interacting with GitHub Actions. Part of our motivation for creating ghapi was to accelerate the development of build, testing and deployment tools that help us in maintaining fastai projects. . We recently started using GitHub Actions to perform a wide variety of tasks automatically like: unit and integration tests, deploying documentation, building Docker containers and Conda packages, sharing releases on Twitter, and much more. This automation is key to maintaining the vast open source fastai ecosystem with very few maintainers. . Since ghapi is central to so many of these tasks, we wanted to stress-test its efficacy against other projects. That’s when we found ghtop. This tool allows you to stream all the public events happening on GitHub to a CLI dashboard. We thought it would be a fun learning experience to refactor this code base with various fastai tools such as ghapi and fastcore, but also try out new libraries like rich. . Features we added to our tools . While exploring ghtop, we added several features to various fastai tools that we found to be generally useful. . ghapi Authentication . We added the function github_auth_device which allows users to authenticate their api client with GitHub interactively in a browser. When we call this function we get the following prompt: . github_auth_device() . First copy your one-time code: 276E-C910 Then visit https://github.com/login/device in your browser, and paste the code when prompted. Shall we try to open the link for you? [y/n] . The browser opens a window that looks like this: . . The function then returns an authenticated token which you can use for various tasks. While this is not the only way to create a token, this is a user friendly way to create a token, especially for those who are not as familiar with GitHub. . ghapi Events . As a result of our explorations with ghtop, we added an event module to ghapi. This is useful for retrieving and inspecting sample events. Inspecting sample events is important as it allows you to prototype GitHub Actions workflows locally. You can sample real events with load_sample_events: . from ghapi.event import load_sample_events evts = load_sample_events() . Individual events are formatted as markdown lists to be human readable in Jupyter: . print(evts[0]) . - id: 14517925737 - type: PushEvent - actor: - id: 17030246 - login: BeckhamL - display_login: BeckhamL - gravatar_id: - url: https://api.github.com/users/BeckhamL - avatar_url: https://avatars.githubusercontent.com/u/17030246? - repo: - id: 154349747 - name: BeckhamL/leetcode - url: https://api.github.com/repos/BeckhamL/leetcode - payload: - push_id: 6194986903 - size: 1 - distinct_size: 1 - ref: refs/heads/master - head: 2055b0fcf22f1c3543e38b60199f6882266d32a5 - before: cb16921949c969b5153a0c23ce8fe516d2c8d773 - commits: - - sha: 2055b0fcf22f1c3543e38b60199f6882266d32a5 - author: - email: beckham.lam@mail.mcgill.ca - name: Beckham Lam - message: Create detectCapital.ts - distinct: True - url: https://api.github.com/repos/BeckhamL/leetcode/commits/2055b0fcf22f1c3543e38b60199f6882266d32a5 - public: True - created_at: 2020-12-13T21:32:34Z . You can also inspect the json data in an event, which are accessible as attributes: . evts[0].type . &#39;PushEvent&#39; . For example, here is the frequency of all full_types in the sample: . x,y = zip(*Counter([o.full_type for o in evts]).most_common()) plt.figure(figsize=(8, 6)) plt.barh(x[::-1],y[::-1]); . We can fetch public events in parallel with GhApi.list_events_parallel. In our experiments, repeatedly calling list_events_parallel is fast enough to fetch all current public activity from all users across the entire GitHub platform. We use this for ghtop. Behind the scenes, list_events_parallel uses Python&#39;s ThreadPoolExecutor to fetch events in parallel - no fancy distributed systems or complicated infrastructure necessary, even at the scale of GitHub! . %time api = GhApi() evts = api.list_events_parallel() len(evts) . CPU times: user 2 µs, sys: 0 ns, total: 2 µs Wall time: 4.29 µs . 240 . Note that the GitHub API is stateless, so successive calls to the API will likely return events already seen. We handle this by using a set operations to filter out events already seen. . ghapi pagination . One of the most cumbersome aspects of fetching lots of data from the GitHub api can be pagination. As mentioned in the documentation, different endpoints have different pagination rules and defaults. Therefore, many api clients offer clunky or incomplete interfaces for pagination. . In ghapi we added an entire module with various tools to make paging easier. Below is an example for retrieving repos for the github org. Without pagination, we can only retrieve a fixed number at a time (by default 30): . api = GhApi() repos = api.repos.list_for_org(&#39;fastai&#39;) len(repos) . 30 . However, to get more we can paginate through paged: . from ghapi.event import paged repos = paged(api.repos.list_for_org, &#39;fastai&#39;) for page in repos: print(len(page), page[0].name) . 30 fast-image 30 fastforest 30 .github 8 tweetrel . You can learn more about this functionality by reading the docs. . fastcore Sparklines . Part of goals for refactoring ghtop were to introduce cool visualizations in the terminal of data. We drew inspiration from projects like bashtop, which have CLI interfaces that look like this: . Concretely, we really liked the idea of sparklines in the terminal. Therefore, we created the ability to show sparklines with fastcore: . from fastcore.utils import sparkline data = [9,6,None,1,4,0,8,15,10] print(f&#39;without &quot;empty_zero&quot;: {sparkline(data, empty_zero=False)}&#39;) print(f&#39; with &quot;empty_zero&quot;: {sparkline(data, empty_zero=True )}&#39;) . without &#34;empty_zero&#34;: ▅▂ ▁▂▁▃▇▅ with &#34;empty_zero&#34;: ▅▂ ▁▂ ▃▇▅ . For more information on this function, read the docs. Later in this post, we will describe how we used Rich to add color and animation to these sparklines. . fastcore EventTimer . Because we wanted streaming event data to automatically populate sparklines, we created EventTimer that constructs a histogram according to a frequency and time span you set. With EventTimer, you can add events with add, and get the number of events and their frequency: . from fastcore.utils import EventTimer from time import sleep import random def _randwait(): yield from (sleep(random.random()/200) for _ in range(100)) c = EventTimer(store=5, span=0.03) for o in _randwait(): c.add(1) print(f&#39;Num Events: {c.events}, Freq/sec: {c.freq:.01f}&#39;) print(&#39;Most recent: &#39;, sparkline(c.hist), *L(c.hist).map(&#39;{:.01f}&#39;)) . Num Events: 6, Freq/sec: 301.1 Most recent: ▃▁▁▇▁ 323.6 274.8 291.3 390.9 283.6 . For more information, see the docs. . CLI Animations With Rich . Rich is an amazing python library that allows you to create beautiful, animated and interactive CLI interfaces. Below is a preview of some its features: . Rich also offers animated elements like spinners: . ... and progress bars: . While this post is not about rich, we highly recommend visiting the repo and the docs to learn more. Rich allows you to create your own custom elements. We created two custom elements - Stats and FixedPanel, which we describe below: . Stats: Sparklines with metrics . Stats renders a group of sparklines along with a spinner and a progress bar. First we define our sparklines, the last argument being a list of event types to count: . from ghtop.richext import * from ghtop.all_rich import * console = Console() s1 = ESpark(&#39;Issues&#39;, &#39;green&#39;, [IssueCommentEvent, IssuesEvent]) s2 = ESpark(&#39;PR&#39;, &#39;red&#39;, [PullRequestEvent, PullRequestReviewCommentEvent, PullRequestReviewEvent]) s3 = ESpark(&#39;Follow&#39;, &#39;blue&#39;, [WatchEvent, StarEvent]) s4 = ESpark(&#39;Other&#39;, &#39;red&#39;) s = Stats([s1,s2,s3,s4], store=5, span=.1, stacked=True) console.print(s) . 🌍 Issues PR Follow Other Quota /min 0.0 0.0 0.0 0.0 ━━━━━━━ 0% . You can add events to update counters and sparklines with add_events: . evts = load_sample_events() s.add_events(evts) console.print(s) . 🌍 Issues PR Follow Other Quota /min 11772 ▁▇ 16546 ▁▇ 5991 ▁▇ 6484 ▁ ━━━━━━━ 0% . You can update the progress bar with the update_prog method: . s.update_prog(50) console.print(s) . 🌍 Issues PR Follow Other Quota /min 4076 ▁▇ 5408 ▁▇ 1834 ▁▇ 5998 ▁ ━━━╸━━━ 50% . Here is what the animated version looks like: . . FixedPanel: A panel with fixed height . A key aspect of ghtop is showing events in different panels. We created FixedPanel to allow us to arrange panels in a grid that we can incrementally add events to: . p = FixedPanel(15, box=box.HORIZONTALS, title=&#39;ghtop&#39;) for e in evts: p.append(e) grid([[p,p]]) . ─────────────────── ghtop ─────────────────── ────────────────── ghtop ─────────────────── 📪 dependabo…closed PR #3 o…herzli…&quot;Bump … 📪 dependabo…closed PR #3 …herzli…&quot;Bump … ⭐ dongjun13 pushed 1 commi…dongjun13/2 ⭐ dongjun13 pushed 1 comm…dongjun13/2 ⭐ admmonito…pushed 1 commi…admmonitors/t… ⭐ admmonito…pushed 1 comm…admmonitors/t… ⭐ randomper…pushed 1 commi…randomperson1… ⭐ randomper…pushed 1 comm…randomperson1… ⭐ ahocevar pushed 6 commi…openlayers/ope… ⭐ ahocevar pushed 6 commi…openlayers/op… 🏭 arjmoto created branch …arjmoto/redux-… 🏭 arjmoto created branch…arjmoto/redux-… 💬 stale[bot…created commen…ironha…&quot;This … 💬 stale[bot…created comme…ironha…&quot;This … ⭐ commit-b0…pushed 1 commi…commit-b0t/co… ⭐ commit-b0…pushed 1 comm…commit-b0t/co… ⭐ yakirgot pushed 2 commi…yakirgot/snake ⭐ yakirgot pushed 2 commi…yakirgot/snake 💬 awolf78 created comment…Impulse…&quot;If yo… 💬 awolf78 created commen…Impulse…&quot;If yo… ⭐ kreus7 pushed 1 commit…kreus7/kreusada… ⭐ kreus7 pushed 1 commit…kreus7/kreusad… ⭐ rgripper pushed 1 commi…rgripper/webco… ⭐ rgripper pushed 1 commi…rgripper/webc… 👀 thelittle…started watchi…ritchie46/pol… 👀 thelittle…started watch…ritchie46/pol… 🏭 adrian698 created branch…adrian698/Test 🏭 adrian698 created branc…adrian698/Test ⭐ mergify[b…pushed 2 commi…spbu-coding/6… ⭐ mergify[b…pushed 2 comm…spbu-coding/6… ───────────────────────────────────────────── ──────────────────────────────────────────── . To learn more about our extensions to rich see these docs. . A demo of ghtop animations . Putting all of this together, we get the following results: . 4 Panels with a sparkline for different types of events: . . single panel with a sparkline . . To learn more about ghtop, see the docs. . Interesting python features used . While making these docs, we used the following python features that at least one person we demoed it to found interesting or didn&#39;t know about. If you have been using python for sometime, you might know about all or most of these features: . yield from . Generators are a powerful feature of python, which are especially useful for iterating through large datasets lazily. . dequeue . f-strings .",
            "url": "http://www.litkm.com/ghtop",
            "relUrl": "/ghtop",
            "date": " • Jan 29, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hello! I’m Charles Dobson, former litigator, now litigation knowledge management lawyer at a law firm in Toronto, Canada. . The legal world is excited about artificial intelligence and developing better data-driven approaches to practice, project management, and business development. I am curious about how AI works “under the hood”, especially machine learning. I am particularly interested in experimenting with using machine learning in litigation, whether for analytics, research, or pricing. . This blog will consist mainly of technical posts where I puzzle my way through concepts and code, but I am also aiming to include a law angle as often as possible. . If you are working on similiar projects or otherwise share this cross-disclipinary interest, please reach out! You can find me on Twitter or LinkedIn. .",
          "url": "http://www.litkm.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://www.litkm.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}