{
  
    
        "post0": {
            "title": "Using Artificial Intelligence to Predict SCOTUS Judging",
            "content": "Introduction . In Prof. Wolfgang Alschner&#39;s fantastic course, Data Science for Lawyers, Lesson 8 uses machine learning to predict Justice Brennan&#39;s voting record. One of the key questions is: if a machine learning model &quot;studies&quot; information about thousands of Justice Brennan&#39;s cases, how well can it predict the way he voted on other cases? . The lesson reviews several different machine learning algorithms.1 This excercise inspired me to attempt to apply a different machine learning approach to the same dataset; namely, deep learning. In this post, I detail the results of this effort. . Justice Brennan . Per Wikipedia, Justice Brennan (1906 – 1997) was an American lawyer and jurist who served as an Associate Justice of the Supreme Court of the United States (SCOTUS) from 1956 to 1990. He was the seventh-longest-serving justice in Supreme Court history, and known for being a leader of the Court&#39;s liberal wing. . The length of Justice Brennan&#39;s tenure is key for present purposes. Since he sat on SCOTUS for so long, he has a lengthy voting record. This is important for &quot;teaching&quot; a machine learning model effectively (the more data, the better). . The Dataset . The dataset is available online at the course website. The data is from The Supreme Court Database. In this database, court decisions are coded for a variety of variables relating to the identification, chronology, background, substance, and outcome of each case. . The dataset is a simple CSV file. Click to view it in a &quot;raw&quot; format. . Below, the first five entries of dataset are printed out. . . Decoded, the first entry indicates: . The case was heard in 1956 (term) | The petitioner (appellant) was a &quot;bank, savings and loan, credit union, investment company&quot; (petitioner) | The respondent was an &quot;agent, fiduciary, trustee, or executor&quot; (respondent) | The court assumed jurisdiction on the basis of a writ of certiorari (jurisdiction) | The case originated from the Pennsylvania Western U.S. District Court (caseOrigin) | The U.S. Court of Appeals, Third Circuit, was the source of the decision SCOTUS reviewed (caseSource) | SCOTUS granted the writ of certiorari in order to &quot;to resolve important or significant question&quot; (certReason) | The subject matter of the controversy related to &quot;cruel and unusual punishment, death penalty (cf. extra legal jury influence, death penalty)&quot; (issue) | The preceding variable was categorized as relating to federalism (issueArea) | Lastly, Justice Brennan voted with the majority (vote) | . Below, additional information from the dataset is set out. . . For present purposes, the most important information shown here is that the dataset contains 4746 entries, i.e. there is information regarding 4746 cases, including whether Justice Brennan voted with the majority or the minority of the SCOTUS panel. . The Deep Learning Model . Machine learning is a subfield of computer science. The basic objective is to program computers to learn so that they can perform tasks for which they were not explicitly programmed.2 . There are many approaches to machine learning, of which deep learning is only one. This approach is based on artificial neural networks, which are a kind of algorithm loosely modelled on neurons in the human brain.3 . The deep learning model I used for this project is based on a model from a lesson in the Codecademy course, Build Deep Learning Models with TensorFlow. This model is coded in a programming language called Python, and uses a deep learning framework from Google, known as Keras (TensorFlow). . My aim was to assemble a model that takes the Brennan dataset as an input, and outputs accurate predictions regarding his voting. . Critically, the model is not pre-programmed with any particular patterns, rules, or guidelines specific to Justice Brennan and the way he voted on SCOTUS. Rather, the model applies the deep learning algorithm to process the dataset and develop, independently, its own &quot;understanding&quot; of his voting history. Based on this understanding, it make predictions. . Forgive me for glossing over a lot of details. But, in simple terms, this is how the model in this project works: . It randomly apportions the dataset into two subsets: one for training, and another for testing (70% for training, 30% for testing). | Then it looks at each case in the training dataset, one-by-one. | With every case, it considers each of the variables (petitioner, respondent, etc), and then predicts whether Justice Brennan voted with the majority or the minority in this particular case. | The model then checks the final column of the dataset: was the prediction correct or not? | It then recalibrates its weighting of each variable based on whether it made a correct or incorrect prediction. When a model works well, this recalibration results in incrementally better (more accurate) predictions. | Once the model has reviewed each of the cases in the training dataset, it then tests itself, case-by-case again, against the second (testing) dataset. This is an important way check against the model merely memorizing the training dataset, as opposed to calibrating its predictive process to enable it to generalize and make accurate predictions about new cases (the test dataset). | After the model cycles through both the training and the testing datasets, it repeats this process over again. Models will do this cycle many times (one hundred, in this instance - but it can be much more). Ideally, the predictive accuracy of the model increases each cycle until it plateaus when it reaches its predictive potential. | . The Results . So how did the model do? . Not too badly. It learned to predict accurately whether Justice Brennan voted with the majority or the minority of the SCOTUS panel with slightly less than 80% accuracy. . If you are interested in the code and the output it produces, click here. . A Twist . Of course, in the &quot;real world&quot; we do not have the benefit of a judge&#39;s entire voting record. Rather, we would have a record of previous votes, from which we would want to predict future votes. . This is the approach taken in Prof. Alschner&#39;s lesson. The dataset is not randomly split. Rather, the machine learning algorithm is trained on the voting record from 1956 until 1979, and then tested against the record from the 1980s. That is, the pre-1980 voting record is used to predict the votes from the 1980s. . How did my deep learning model do when the dataset was likewise apportioned? Performance dropped. At best, the model achieved about 69% accuracy. . I tweeted about this and Prof. Alschner kindly commented, noting the pre-1980 variables seem to miss something important for predicting the post-1980 voting. . This made me do some digging that I should have done at the outset (in my defence, I am a hobbyist who did not know any better at the time!). . Below is a graph showing Justice Brennan&#39;s votes over the entire dataset: . . As you can see, Justice Brennan voted with the majority slightly less than 80% of the time over the course of his entire SCOTUS tenure. . When we look at his record from the 1950s until the end of the 1970s, we see that he voted with the majority slightly more than 80% of the time: . . Finally, let&#39;s look at his voting record for the 1980s only: . . We now see a big drop! He voted with the majority less than 70% of the time. This may explain why the model&#39;s prediction accuracy dropped when the dataset was split to train on the pre-1980s data and test on the 1980s data. . Concluding Thoughts . Some final thoughts: . Sometimes a simple approach will yield valuable insight. Just graphing Justice&#39;s Brennan&#39;s voting history provides enough information to make some reasonably accurate predictions. No fancy machine learning algorithms required. | That said, I still consider this experiment a success. The model appears to work, for one thing. At the outset, it &quot;knows&quot; nothing about Justice Brennan&#39;s voting record; it is simply programmed to process the dataset in a certain way. On completion, the model provides reasonably accurate predictions - better than a coin toss, in any event! | What about using these techniques in legal practice? Litigation analytics is already &quot;a thing&quot;, especially in the US. In Canada, unfortunately, we suffer from a deficit of publicly available litigation data, so progress is much slower. For example, do not have an equivalent to the Supreme Court Database, discussed above, for data about the Supreme Court of Canada. | . Thanks for reading! Did I make a mistake? Does something not make sense? Please reach out. . 1. These algorithms are naive bayes, support vector machines, and K-nearest neighbor.↩ . 2. Andrew Trask, Grokking Deep Learning (Shelter Island, NY: Manning Publications, 2019), p. 11↩ . 3. Ibid., p. 10↩ .",
            "url": "http://www.litkm.com/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html",
            "relUrl": "/artificial%20intelligence/machine%20learning/deep%20learning/litigation/analytics/2021/02/04/_02_04_AI_and_SCOTUS_Judging.html",
            "date": " • Feb 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "ghtop redux",
            "content": ". Introduction . We recently refactored the CLI tool ghtop, created by the CEO of GitHub, Nat Friedman. Nat even described our refactor as a “tour de force”. This post describes what we learned along the way. . Motivation . Recently, we released ghapi, a new python client for the GitHub API. ghapi provides unparalleled ease of access to the GitHub api, as well as utilities for interacting with GitHub Actions. Part of our motivation for creating ghapi was to accelerate the development of build, testing and deployment tools that help us in maintaining fastai projects. . We recently started using GitHub Actions to perform a wide variety of tasks automatically like: unit and integration tests, deploying documentation, building Docker containers and Conda packages, sharing releases on Twitter, and much more. This automation is key to maintaining the vast open source fastai ecosystem with very few maintainers. . Since ghapi is central to so many of these tasks, we wanted to stress-test its efficacy against other projects. That’s when we found ghtop. This tool allows you to stream all the public events happening on GitHub to a CLI dashboard. We thought it would be a fun learning experience to refactor this code base with various fastai tools such as ghapi and fastcore, but also try out new libraries like rich. . Features we added to our tools . While exploring ghtop, we added several features to various fastai tools that we found to be generally useful. . ghapi Authentication . We added the function github_auth_device which allows users to authenticate their api client with GitHub interactively in a browser. When we call this function we get the following prompt: . github_auth_device() . First copy your one-time code: 276E-C910 Then visit https://github.com/login/device in your browser, and paste the code when prompted. Shall we try to open the link for you? [y/n] . The browser opens a window that looks like this: . . The function then returns an authenticated token which you can use for various tasks. While this is not the only way to create a token, this is a user friendly way to create a token, especially for those who are not as familiar with GitHub. . ghapi Events . As a result of our explorations with ghtop, we added an event module to ghapi. This is useful for retrieving and inspecting sample events. Inspecting sample events is important as it allows you to prototype GitHub Actions workflows locally. You can sample real events with load_sample_events: . from ghapi.event import load_sample_events evts = load_sample_events() . Individual events are formatted as markdown lists to be human readable in Jupyter: . print(evts[0]) . - id: 14517925737 - type: PushEvent - actor: - id: 17030246 - login: BeckhamL - display_login: BeckhamL - gravatar_id: - url: https://api.github.com/users/BeckhamL - avatar_url: https://avatars.githubusercontent.com/u/17030246? - repo: - id: 154349747 - name: BeckhamL/leetcode - url: https://api.github.com/repos/BeckhamL/leetcode - payload: - push_id: 6194986903 - size: 1 - distinct_size: 1 - ref: refs/heads/master - head: 2055b0fcf22f1c3543e38b60199f6882266d32a5 - before: cb16921949c969b5153a0c23ce8fe516d2c8d773 - commits: - - sha: 2055b0fcf22f1c3543e38b60199f6882266d32a5 - author: - email: beckham.lam@mail.mcgill.ca - name: Beckham Lam - message: Create detectCapital.ts - distinct: True - url: https://api.github.com/repos/BeckhamL/leetcode/commits/2055b0fcf22f1c3543e38b60199f6882266d32a5 - public: True - created_at: 2020-12-13T21:32:34Z . You can also inspect the json data in an event, which are accessible as attributes: . evts[0].type . &#39;PushEvent&#39; . For example, here is the frequency of all full_types in the sample: . x,y = zip(*Counter([o.full_type for o in evts]).most_common()) plt.figure(figsize=(8, 6)) plt.barh(x[::-1],y[::-1]); . We can fetch public events in parallel with GhApi.list_events_parallel. In our experiments, repeatedly calling list_events_parallel is fast enough to fetch all current public activity from all users across the entire GitHub platform. We use this for ghtop. Behind the scenes, list_events_parallel uses Python&#39;s ThreadPoolExecutor to fetch events in parallel - no fancy distributed systems or complicated infrastructure necessary, even at the scale of GitHub! . %time api = GhApi() evts = api.list_events_parallel() len(evts) . CPU times: user 2 µs, sys: 0 ns, total: 2 µs Wall time: 4.29 µs . 240 . Note that the GitHub API is stateless, so successive calls to the API will likely return events already seen. We handle this by using a set operations to filter out events already seen. . ghapi pagination . One of the most cumbersome aspects of fetching lots of data from the GitHub api can be pagination. As mentioned in the documentation, different endpoints have different pagination rules and defaults. Therefore, many api clients offer clunky or incomplete interfaces for pagination. . In ghapi we added an entire module with various tools to make paging easier. Below is an example for retrieving repos for the github org. Without pagination, we can only retrieve a fixed number at a time (by default 30): . api = GhApi() repos = api.repos.list_for_org(&#39;fastai&#39;) len(repos) . 30 . However, to get more we can paginate through paged: . from ghapi.event import paged repos = paged(api.repos.list_for_org, &#39;fastai&#39;) for page in repos: print(len(page), page[0].name) . 30 fast-image 30 fastforest 30 .github 8 tweetrel . You can learn more about this functionality by reading the docs. . fastcore Sparklines . Part of goals for refactoring ghtop were to introduce cool visualizations in the terminal of data. We drew inspiration from projects like bashtop, which have CLI interfaces that look like this: . Concretely, we really liked the idea of sparklines in the terminal. Therefore, we created the ability to show sparklines with fastcore: . from fastcore.utils import sparkline data = [9,6,None,1,4,0,8,15,10] print(f&#39;without &quot;empty_zero&quot;: {sparkline(data, empty_zero=False)}&#39;) print(f&#39; with &quot;empty_zero&quot;: {sparkline(data, empty_zero=True )}&#39;) . without &#34;empty_zero&#34;: ▅▂ ▁▂▁▃▇▅ with &#34;empty_zero&#34;: ▅▂ ▁▂ ▃▇▅ . For more information on this function, read the docs. Later in this post, we will describe how we used Rich to add color and animation to these sparklines. . fastcore EventTimer . Because we wanted streaming event data to automatically populate sparklines, we created EventTimer that constructs a histogram according to a frequency and time span you set. With EventTimer, you can add events with add, and get the number of events and their frequency: . from fastcore.utils import EventTimer from time import sleep import random def _randwait(): yield from (sleep(random.random()/200) for _ in range(100)) c = EventTimer(store=5, span=0.03) for o in _randwait(): c.add(1) print(f&#39;Num Events: {c.events}, Freq/sec: {c.freq:.01f}&#39;) print(&#39;Most recent: &#39;, sparkline(c.hist), *L(c.hist).map(&#39;{:.01f}&#39;)) . Num Events: 6, Freq/sec: 301.1 Most recent: ▃▁▁▇▁ 323.6 274.8 291.3 390.9 283.6 . For more information, see the docs. . CLI Animations With Rich . Rich is an amazing python library that allows you to create beautiful, animated and interactive CLI interfaces. Below is a preview of some its features: . Rich also offers animated elements like spinners: . ... and progress bars: . While this post is not about rich, we highly recommend visiting the repo and the docs to learn more. Rich allows you to create your own custom elements. We created two custom elements - Stats and FixedPanel, which we describe below: . Stats: Sparklines with metrics . Stats renders a group of sparklines along with a spinner and a progress bar. First we define our sparklines, the last argument being a list of event types to count: . from ghtop.richext import * from ghtop.all_rich import * console = Console() s1 = ESpark(&#39;Issues&#39;, &#39;green&#39;, [IssueCommentEvent, IssuesEvent]) s2 = ESpark(&#39;PR&#39;, &#39;red&#39;, [PullRequestEvent, PullRequestReviewCommentEvent, PullRequestReviewEvent]) s3 = ESpark(&#39;Follow&#39;, &#39;blue&#39;, [WatchEvent, StarEvent]) s4 = ESpark(&#39;Other&#39;, &#39;red&#39;) s = Stats([s1,s2,s3,s4], store=5, span=.1, stacked=True) console.print(s) . 🌍 Issues PR Follow Other Quota /min 0.0 0.0 0.0 0.0 ━━━━━━━ 0% . You can add events to update counters and sparklines with add_events: . evts = load_sample_events() s.add_events(evts) console.print(s) . 🌍 Issues PR Follow Other Quota /min 11772 ▁▇ 16546 ▁▇ 5991 ▁▇ 6484 ▁ ━━━━━━━ 0% . You can update the progress bar with the update_prog method: . s.update_prog(50) console.print(s) . 🌍 Issues PR Follow Other Quota /min 4076 ▁▇ 5408 ▁▇ 1834 ▁▇ 5998 ▁ ━━━╸━━━ 50% . Here is what the animated version looks like: . . FixedPanel: A panel with fixed height . A key aspect of ghtop is showing events in different panels. We created FixedPanel to allow us to arrange panels in a grid that we can incrementally add events to: . p = FixedPanel(15, box=box.HORIZONTALS, title=&#39;ghtop&#39;) for e in evts: p.append(e) grid([[p,p]]) . ─────────────────── ghtop ─────────────────── ────────────────── ghtop ─────────────────── 📪 dependabo…closed PR #3 o…herzli…&quot;Bump … 📪 dependabo…closed PR #3 …herzli…&quot;Bump … ⭐ dongjun13 pushed 1 commi…dongjun13/2 ⭐ dongjun13 pushed 1 comm…dongjun13/2 ⭐ admmonito…pushed 1 commi…admmonitors/t… ⭐ admmonito…pushed 1 comm…admmonitors/t… ⭐ randomper…pushed 1 commi…randomperson1… ⭐ randomper…pushed 1 comm…randomperson1… ⭐ ahocevar pushed 6 commi…openlayers/ope… ⭐ ahocevar pushed 6 commi…openlayers/op… 🏭 arjmoto created branch …arjmoto/redux-… 🏭 arjmoto created branch…arjmoto/redux-… 💬 stale[bot…created commen…ironha…&quot;This … 💬 stale[bot…created comme…ironha…&quot;This … ⭐ commit-b0…pushed 1 commi…commit-b0t/co… ⭐ commit-b0…pushed 1 comm…commit-b0t/co… ⭐ yakirgot pushed 2 commi…yakirgot/snake ⭐ yakirgot pushed 2 commi…yakirgot/snake 💬 awolf78 created comment…Impulse…&quot;If yo… 💬 awolf78 created commen…Impulse…&quot;If yo… ⭐ kreus7 pushed 1 commit…kreus7/kreusada… ⭐ kreus7 pushed 1 commit…kreus7/kreusad… ⭐ rgripper pushed 1 commi…rgripper/webco… ⭐ rgripper pushed 1 commi…rgripper/webc… 👀 thelittle…started watchi…ritchie46/pol… 👀 thelittle…started watch…ritchie46/pol… 🏭 adrian698 created branch…adrian698/Test 🏭 adrian698 created branc…adrian698/Test ⭐ mergify[b…pushed 2 commi…spbu-coding/6… ⭐ mergify[b…pushed 2 comm…spbu-coding/6… ───────────────────────────────────────────── ──────────────────────────────────────────── . To learn more about our extensions to rich see these docs. . A demo of ghtop animations . Putting all of this together, we get the following results: . 4 Panels with a sparkline for different types of events: . . single panel with a sparkline . . To learn more about ghtop, see the docs. . Interesting python features used . While making these docs, we used the following python features that at least one person we demoed it to found interesting or didn&#39;t know about. If you have been using python for sometime, you might know about all or most of these features: . yield from . Generators are a powerful feature of python, which are especially useful for iterating through large datasets lazily. . dequeue . f-strings .",
            "url": "http://www.litkm.com/ghtop",
            "relUrl": "/ghtop",
            "date": " • Jan 29, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Charles Dobson. I am a former litigator, now litigation knowledge management lawyer at a law firm in Toronto, Canada. . The legal world is excited about artificial intelligence and developing better data-driven approaches to practice, project management, and business development. I am curious about how AI works “under the hood”, especially machine learning. I am particularly interested in experimenting with using machine learning in litigation, whether for analytics, research, or business development. . This blog will consist mainly of technical posts where I puzzle my way through concepts and code, but I am also aiming to include a law angle as often as possible. . If you are working on similiar projects or otherwise share this cross-disclipinary interest, please reach out! You can find me on Twitter or LinkedIn. .",
          "url": "http://www.litkm.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://www.litkm.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}